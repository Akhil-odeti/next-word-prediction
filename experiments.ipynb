{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data preprocessing\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7507"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Sherlock Holmes.txt\",\"r\") as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "# tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words  = len(tokenizer.word_index) +1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'i': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'a': 6,\n",
       " 'in': 7,\n",
       " 'that': 8,\n",
       " 'it': 9,\n",
       " 'he': 10,\n",
       " 'you': 11,\n",
       " 'was': 12,\n",
       " 'his': 13,\n",
       " 'is': 14,\n",
       " 'my': 15,\n",
       " 'have': 16,\n",
       " 'as': 17,\n",
       " 'had': 18,\n",
       " 'with': 19,\n",
       " 'which': 20,\n",
       " 'at': 21,\n",
       " 'for': 22,\n",
       " 'but': 23,\n",
       " 'not': 24,\n",
       " 'be': 25,\n",
       " 'me': 26,\n",
       " 'we': 27,\n",
       " 'from': 28,\n",
       " 'there': 29,\n",
       " 'upon': 30,\n",
       " 'this': 31,\n",
       " 'said': 32,\n",
       " 'holmes': 33,\n",
       " 'so': 34,\n",
       " 'him': 35,\n",
       " 'her': 36,\n",
       " 'very': 37,\n",
       " 'she': 38,\n",
       " 'been': 39,\n",
       " 'on': 40,\n",
       " 'all': 41,\n",
       " 'no': 42,\n",
       " 'one': 43,\n",
       " 'then': 44,\n",
       " 'your': 45,\n",
       " 'what': 46,\n",
       " 'were': 47,\n",
       " 'by': 48,\n",
       " 'are': 49,\n",
       " 'an': 50,\n",
       " \"'\": 51,\n",
       " 'out': 52,\n",
       " 'when': 53,\n",
       " 'would': 54,\n",
       " 'up': 55,\n",
       " 'man': 56,\n",
       " 'has': 57,\n",
       " 'into': 58,\n",
       " 'some': 59,\n",
       " 'will': 60,\n",
       " 'do': 61,\n",
       " 'could': 62,\n",
       " 'little': 63,\n",
       " 'who': 64,\n",
       " 'mr': 65,\n",
       " 'if': 66,\n",
       " 'see': 67,\n",
       " 'now': 68,\n",
       " 'down': 69,\n",
       " 'our': 70,\n",
       " 'well': 71,\n",
       " 'they': 72,\n",
       " 'or': 73,\n",
       " 'us': 74,\n",
       " 'over': 75,\n",
       " 'may': 76,\n",
       " 'should': 77,\n",
       " 'am': 78,\n",
       " 'know': 79,\n",
       " 'before': 80,\n",
       " 'more': 81,\n",
       " 'come': 82,\n",
       " 'about': 83,\n",
       " 'time': 84,\n",
       " 'can': 85,\n",
       " 'did': 86,\n",
       " 'shall': 87,\n",
       " 'think': 88,\n",
       " 'must': 89,\n",
       " 'than': 90,\n",
       " 'room': 91,\n",
       " 'two': 92,\n",
       " 'only': 93,\n",
       " 'other': 94,\n",
       " 'came': 95,\n",
       " 'how': 96,\n",
       " 'back': 97,\n",
       " 'them': 98,\n",
       " 'here': 99,\n",
       " 'good': 100,\n",
       " 'just': 101,\n",
       " 'hand': 102,\n",
       " 'case': 103,\n",
       " 'face': 104,\n",
       " 'might': 105,\n",
       " 'any': 106,\n",
       " 'way': 107,\n",
       " 'door': 108,\n",
       " 'heard': 109,\n",
       " 'where': 110,\n",
       " 'such': 111,\n",
       " 'matter': 112,\n",
       " 'made': 113,\n",
       " 'yes': 114,\n",
       " 'much': 115,\n",
       " 'nothing': 116,\n",
       " 'day': 117,\n",
       " 'sherlock': 118,\n",
       " 'never': 119,\n",
       " 'found': 120,\n",
       " 'night': 121,\n",
       " 'right': 122,\n",
       " 'away': 123,\n",
       " 'however': 124,\n",
       " 'own': 125,\n",
       " 'house': 126,\n",
       " 'st': 127,\n",
       " 'quite': 128,\n",
       " 'like': 129,\n",
       " 'last': 130,\n",
       " 'after': 131,\n",
       " 'left': 132,\n",
       " 'morning': 133,\n",
       " 'their': 134,\n",
       " 'street': 135,\n",
       " 'go': 136,\n",
       " 'say': 137,\n",
       " 'through': 138,\n",
       " 'yet': 139,\n",
       " 'watson': 140,\n",
       " 'side': 141,\n",
       " 'took': 142,\n",
       " 'long': 143,\n",
       " 'its': 144,\n",
       " 'every': 145,\n",
       " 'small': 146,\n",
       " 'father': 147,\n",
       " 'eyes': 148,\n",
       " 'take': 149,\n",
       " 'first': 150,\n",
       " 'tell': 151,\n",
       " 'these': 152,\n",
       " 'asked': 153,\n",
       " 'most': 154,\n",
       " 'seen': 155,\n",
       " 'still': 156,\n",
       " 'oh': 157,\n",
       " 'saw': 158,\n",
       " 'too': 159,\n",
       " 'find': 160,\n",
       " 'few': 161,\n",
       " 'those': 162,\n",
       " 'myself': 163,\n",
       " 'light': 164,\n",
       " 'old': 165,\n",
       " 'once': 166,\n",
       " 'off': 167,\n",
       " 'business': 168,\n",
       " 'young': 169,\n",
       " 'having': 170,\n",
       " 'himself': 171,\n",
       " 'while': 172,\n",
       " 'round': 173,\n",
       " 'years': 174,\n",
       " 'remarked': 175,\n",
       " 'until': 176,\n",
       " 'friend': 177,\n",
       " 'even': 178,\n",
       " 'head': 179,\n",
       " 'thought': 180,\n",
       " 'make': 181,\n",
       " 'window': 182,\n",
       " 'chair': 183,\n",
       " 'seemed': 184,\n",
       " 'lady': 185,\n",
       " 'hands': 186,\n",
       " 'indeed': 187,\n",
       " 'though': 188,\n",
       " 'something': 189,\n",
       " 'ever': 190,\n",
       " 'put': 191,\n",
       " 'without': 192,\n",
       " 'sir': 193,\n",
       " 'half': 194,\n",
       " 'why': 195,\n",
       " 'three': 196,\n",
       " 'done': 197,\n",
       " 'get': 198,\n",
       " 'open': 199,\n",
       " 'course': 200,\n",
       " 'name': 201,\n",
       " 'let': 202,\n",
       " 'went': 203,\n",
       " 'between': 204,\n",
       " 'rather': 205,\n",
       " 'same': 206,\n",
       " 'always': 207,\n",
       " 'again': 208,\n",
       " 'great': 209,\n",
       " 'miss': 210,\n",
       " 'look': 211,\n",
       " 'red': 212,\n",
       " 'woman': 213,\n",
       " 'doubt': 214,\n",
       " 'hat': 215,\n",
       " 'give': 216,\n",
       " 'cried': 217,\n",
       " 'mind': 218,\n",
       " 'home': 219,\n",
       " 'knew': 220,\n",
       " 'answered': 221,\n",
       " 'enough': 222,\n",
       " 'also': 223,\n",
       " 'work': 224,\n",
       " 'perhaps': 225,\n",
       " 'within': 226,\n",
       " 'got': 227,\n",
       " 'table': 228,\n",
       " 'paper': 229,\n",
       " 'far': 230,\n",
       " 'sat': 231,\n",
       " 'against': 232,\n",
       " 'black': 233,\n",
       " 'anything': 234,\n",
       " 'end': 235,\n",
       " 'papers': 236,\n",
       " 'looking': 237,\n",
       " 'really': 238,\n",
       " 'place': 239,\n",
       " 'police': 240,\n",
       " 'looked': 241,\n",
       " 'understand': 242,\n",
       " 'already': 243,\n",
       " 'being': 244,\n",
       " 'strange': 245,\n",
       " 'gave': 246,\n",
       " 'life': 247,\n",
       " 'behind': 248,\n",
       " 'fire': 249,\n",
       " 'wife': 250,\n",
       " 'point': 251,\n",
       " 'minutes': 252,\n",
       " 'suddenly': 253,\n",
       " 'possible': 254,\n",
       " 'simon': 255,\n",
       " 'hardly': 256,\n",
       " 'certainly': 257,\n",
       " 'many': 258,\n",
       " 'better': 259,\n",
       " 'brought': 260,\n",
       " 'lay': 261,\n",
       " 'lord': 262,\n",
       " 'front': 263,\n",
       " 'turned': 264,\n",
       " 'wish': 265,\n",
       " 'words': 266,\n",
       " 'lestrade': 267,\n",
       " 'baker': 268,\n",
       " 'gentleman': 269,\n",
       " 'help': 270,\n",
       " 'both': 271,\n",
       " 'cannot': 272,\n",
       " 'under': 273,\n",
       " 'dear': 274,\n",
       " 'london': 275,\n",
       " 'thing': 276,\n",
       " 'doctor': 277,\n",
       " 'pray': 278,\n",
       " 'men': 279,\n",
       " 'four': 280,\n",
       " 'save': 281,\n",
       " 'told': 282,\n",
       " 'yourself': 283,\n",
       " 'clear': 284,\n",
       " 'call': 285,\n",
       " 'another': 286,\n",
       " 'five': 287,\n",
       " 'facts': 288,\n",
       " 'less': 289,\n",
       " 'does': 290,\n",
       " 'interest': 291,\n",
       " 'leave': 292,\n",
       " 'mccarthy': 293,\n",
       " 'whole': 294,\n",
       " 'since': 295,\n",
       " 'note': 296,\n",
       " 'money': 297,\n",
       " 'whom': 298,\n",
       " 'days': 299,\n",
       " 'set': 300,\n",
       " 'among': 301,\n",
       " 'across': 302,\n",
       " 'fellow': 303,\n",
       " 'met': 304,\n",
       " 'dark': 305,\n",
       " 'country': 306,\n",
       " 'read': 307,\n",
       " 'moment': 308,\n",
       " 'during': 309,\n",
       " 'whether': 310,\n",
       " 'stone': 311,\n",
       " 'singular': 312,\n",
       " 'companion': 313,\n",
       " 'returned': 314,\n",
       " 'believe': 315,\n",
       " 'either': 316,\n",
       " 'large': 317,\n",
       " 'dr': 318,\n",
       " 'none': 319,\n",
       " 'sitting': 320,\n",
       " 'question': 321,\n",
       " 'use': 322,\n",
       " 'gone': 323,\n",
       " 'passed': 324,\n",
       " 'new': 325,\n",
       " 'hear': 326,\n",
       " 'else': 327,\n",
       " \"it's\": 328,\n",
       " 'floor': 329,\n",
       " 'least': 330,\n",
       " 'near': 331,\n",
       " 'used': 332,\n",
       " 'bed': 333,\n",
       " 'son': 334,\n",
       " 'felt': 335,\n",
       " 'word': 336,\n",
       " 'stood': 337,\n",
       " 'seven': 338,\n",
       " 'together': 339,\n",
       " \"o'clock\": 340,\n",
       " 'entered': 341,\n",
       " 'sure': 342,\n",
       " 'laid': 343,\n",
       " 'station': 344,\n",
       " 'cry': 345,\n",
       " 'waiting': 346,\n",
       " 'letter': 347,\n",
       " 'hair': 348,\n",
       " 'goose': 349,\n",
       " 'lamp': 350,\n",
       " 'strong': 351,\n",
       " 'marriage': 352,\n",
       " 'threw': 353,\n",
       " 'corner': 354,\n",
       " \"don't\": 355,\n",
       " 'hour': 356,\n",
       " 'death': 357,\n",
       " 'coat': 358,\n",
       " 'able': 359,\n",
       " 'letters': 360,\n",
       " 'soon': 361,\n",
       " 'instant': 362,\n",
       " \"'i\": 363,\n",
       " 'evening': 364,\n",
       " 'several': 365,\n",
       " 'forward': 366,\n",
       " 'going': 367,\n",
       " 'inspector': 368,\n",
       " 'things': 369,\n",
       " 'crime': 370,\n",
       " 'family': 371,\n",
       " 'part': 372,\n",
       " 'visitor': 373,\n",
       " 'want': 374,\n",
       " 'present': 375,\n",
       " 'photograph': 376,\n",
       " 'road': 377,\n",
       " 'cab': 378,\n",
       " 'john': 379,\n",
       " 'held': 380,\n",
       " 'headed': 381,\n",
       " 'each': 382,\n",
       " 'attention': 383,\n",
       " 'bell': 384,\n",
       " 'ago': 385,\n",
       " 'true': 386,\n",
       " 'given': 387,\n",
       " 'heavy': 388,\n",
       " 'sound': 389,\n",
       " 'best': 390,\n",
       " 'feet': 391,\n",
       " 'deep': 392,\n",
       " 'taken': 393,\n",
       " 'king': 394,\n",
       " 'white': 395,\n",
       " 'known': 396,\n",
       " 'became': 397,\n",
       " 'absolutely': 398,\n",
       " 'drove': 399,\n",
       " 'hard': 400,\n",
       " 'mrs': 401,\n",
       " 'rushed': 402,\n",
       " 'keep': 403,\n",
       " 'fact': 404,\n",
       " 'sister': 405,\n",
       " 'colonel': 406,\n",
       " 'story': 407,\n",
       " 'eye': 408,\n",
       " 'imagine': 409,\n",
       " 'six': 410,\n",
       " 'address': 411,\n",
       " 'client': 412,\n",
       " 'year': 413,\n",
       " 'turn': 414,\n",
       " 'air': 415,\n",
       " 'ten': 416,\n",
       " 'ah': 417,\n",
       " 'obvious': 418,\n",
       " 'clair': 419,\n",
       " 'spoke': 420,\n",
       " 'week': 421,\n",
       " 'rooms': 422,\n",
       " 'steps': 423,\n",
       " 'followed': 424,\n",
       " 'opened': 425,\n",
       " 'walked': 426,\n",
       " 'likely': 427,\n",
       " 'twenty': 428,\n",
       " 'hope': 429,\n",
       " 'ran': 430,\n",
       " 'thank': 431,\n",
       " 'square': 432,\n",
       " 'bird': 433,\n",
       " 'idea': 434,\n",
       " 'hosmer': 435,\n",
       " 'high': 436,\n",
       " 'nature': 437,\n",
       " 'late': 438,\n",
       " 'manner': 439,\n",
       " 'lost': 440,\n",
       " 'cases': 441,\n",
       " 'called': 442,\n",
       " 'second': 443,\n",
       " 'fear': 444,\n",
       " 'pocket': 445,\n",
       " 'started': 446,\n",
       " 'sort': 447,\n",
       " 'coming': 448,\n",
       " 'dressed': 449,\n",
       " 'anyone': 450,\n",
       " 'carriage': 451,\n",
       " 'silence': 452,\n",
       " 'ask': 453,\n",
       " 'office': 454,\n",
       " 'town': 455,\n",
       " 'wedding': 456,\n",
       " 'blue': 457,\n",
       " 'cold': 458,\n",
       " 'led': 459,\n",
       " 'step': 460,\n",
       " 'past': 461,\n",
       " 'rose': 462,\n",
       " 'glanced': 463,\n",
       " 'sprang': 464,\n",
       " 'ground': 465,\n",
       " 'married': 466,\n",
       " 'bring': 467,\n",
       " 'beside': 468,\n",
       " 'quietly': 469,\n",
       " 'god': 470,\n",
       " 'drive': 471,\n",
       " 'chance': 472,\n",
       " 'turner': 473,\n",
       " 'easy': 474,\n",
       " 'struck': 475,\n",
       " 'drawn': 476,\n",
       " 'reason': 477,\n",
       " 'wilson': 478,\n",
       " 'body': 479,\n",
       " 'city': 480,\n",
       " 'ready': 481,\n",
       " 'windibank': 482,\n",
       " 'mystery': 483,\n",
       " 'clothes': 484,\n",
       " 'written': 485,\n",
       " 'interesting': 486,\n",
       " 'appeared': 487,\n",
       " 'lodge': 488,\n",
       " 'quick': 489,\n",
       " 'remarkable': 490,\n",
       " 'began': 491,\n",
       " 'others': 492,\n",
       " 'seems': 493,\n",
       " 'mean': 494,\n",
       " 'hours': 495,\n",
       " 'remember': 496,\n",
       " 'dead': 497,\n",
       " 'heart': 498,\n",
       " 'mine': 499,\n",
       " 'above': 500,\n",
       " 'train': 501,\n",
       " 'grey': 502,\n",
       " 'considerable': 503,\n",
       " 'thin': 504,\n",
       " 'angel': 505,\n",
       " 'stepfather': 506,\n",
       " 'mother': 507,\n",
       " 'breakfast': 508,\n",
       " 'pool': 509,\n",
       " 'frank': 510,\n",
       " 'k': 511,\n",
       " 'neville': 512,\n",
       " 'stoner': 513,\n",
       " 'adventure': 514,\n",
       " 'account': 515,\n",
       " 'simple': 516,\n",
       " 'because': 517,\n",
       " 'ha': 518,\n",
       " 'single': 519,\n",
       " 'carried': 520,\n",
       " 'voice': 521,\n",
       " 'doing': 522,\n",
       " 'windows': 523,\n",
       " 'people': 524,\n",
       " 'whose': 525,\n",
       " 'important': 526,\n",
       " 'hurried': 527,\n",
       " 'poor': 528,\n",
       " 'box': 529,\n",
       " 'rest': 530,\n",
       " 'afraid': 531,\n",
       " 'advertisement': 532,\n",
       " 'court': 533,\n",
       " 'effect': 534,\n",
       " 'sight': 535,\n",
       " 'water': 536,\n",
       " 'low': 537,\n",
       " 'points': 538,\n",
       " 'talk': 539,\n",
       " 'happened': 540,\n",
       " 'james': 541,\n",
       " 'league': 542,\n",
       " 'position': 543,\n",
       " 'remained': 544,\n",
       " 'finally': 545,\n",
       " 'order': 546,\n",
       " 'laughing': 547,\n",
       " 'observed': 548,\n",
       " 'peculiar': 549,\n",
       " 'sent': 550,\n",
       " 'glancing': 551,\n",
       " 'passage': 552,\n",
       " 'alone': 553,\n",
       " 'person': 554,\n",
       " 'sign': 555,\n",
       " 'laughed': 556,\n",
       " 'daughter': 557,\n",
       " 'afternoon': 558,\n",
       " 'maid': 559,\n",
       " 'standing': 560,\n",
       " 'towards': 561,\n",
       " 'cause': 562,\n",
       " 'entirely': 563,\n",
       " 'ourselves': 564,\n",
       " 'showed': 565,\n",
       " 'making': 566,\n",
       " 'husband': 567,\n",
       " 'finger': 568,\n",
       " 'earth': 569,\n",
       " 'short': 570,\n",
       " 'pipe': 571,\n",
       " 'instantly': 572,\n",
       " 'cut': 573,\n",
       " \"i'll\": 574,\n",
       " 'occurred': 575,\n",
       " 'hatherley': 576,\n",
       " 'evidence': 577,\n",
       " 'geese': 578,\n",
       " 'boscombe': 579,\n",
       " 'thumb': 580,\n",
       " 'irene': 581,\n",
       " 'adler': 582,\n",
       " 'machine': 583,\n",
       " 'problem': 584,\n",
       " 'observe': 585,\n",
       " 'glance': 586,\n",
       " 'outside': 587,\n",
       " 'england': 588,\n",
       " 'shoulders': 589,\n",
       " 'speak': 590,\n",
       " 'slowly': 591,\n",
       " 'majesty': 592,\n",
       " 'next': 593,\n",
       " 'line': 594,\n",
       " 'suppose': 595,\n",
       " 'reached': 596,\n",
       " 'details': 597,\n",
       " 'pulled': 598,\n",
       " 'afterwards': 599,\n",
       " 'quiet': 600,\n",
       " 'direction': 601,\n",
       " 'need': 602,\n",
       " 'fell': 603,\n",
       " 'events': 604,\n",
       " 'weeks': 605,\n",
       " 'colour': 606,\n",
       " 'bright': 607,\n",
       " 'yard': 608,\n",
       " 'seeing': 609,\n",
       " 'love': 610,\n",
       " 'placed': 611,\n",
       " 'lit': 612,\n",
       " 'figure': 613,\n",
       " 'girl': 614,\n",
       " 'appears': 615,\n",
       " 'times': 616,\n",
       " 'importance': 617,\n",
       " 'means': 618,\n",
       " 'brown': 619,\n",
       " 'sharp': 620,\n",
       " 'hundred': 621,\n",
       " 'dress': 622,\n",
       " 'caught': 623,\n",
       " 'surprise': 624,\n",
       " 'secret': 625,\n",
       " 'serious': 626,\n",
       " 'news': 627,\n",
       " 'close': 628,\n",
       " 'bedroom': 629,\n",
       " 'garden': 630,\n",
       " 'wait': 631,\n",
       " 'arrived': 632,\n",
       " 'whispered': 633,\n",
       " 'witness': 634,\n",
       " 'fresh': 635,\n",
       " 'return': 636,\n",
       " 'safe': 637,\n",
       " 'closed': 638,\n",
       " 'lips': 639,\n",
       " 'slight': 640,\n",
       " 'says': 641,\n",
       " 'answer': 642,\n",
       " 'advice': 643,\n",
       " 'opinion': 644,\n",
       " 'danger': 645,\n",
       " 'sudden': 646,\n",
       " 'coroner': 647,\n",
       " 'miles': 648,\n",
       " 'openshaw': 649,\n",
       " 'band': 650,\n",
       " 'twice': 651,\n",
       " 'shown': 652,\n",
       " 'glad': 653,\n",
       " 'armchair': 654,\n",
       " 'fashion': 655,\n",
       " 'top': 656,\n",
       " 'explain': 657,\n",
       " 'eight': 658,\n",
       " 'matters': 659,\n",
       " 'wrote': 660,\n",
       " 'german': 661,\n",
       " 'boy': 662,\n",
       " 'impression': 663,\n",
       " 'appearance': 664,\n",
       " 'broad': 665,\n",
       " 'promise': 666,\n",
       " 'follow': 667,\n",
       " 'gold': 668,\n",
       " 'view': 669,\n",
       " 'listened': 670,\n",
       " 'object': 671,\n",
       " 'church': 672,\n",
       " 'dropped': 673,\n",
       " \"won't\": 674,\n",
       " 'meet': 675,\n",
       " 'smoke': 676,\n",
       " \"holmes'\": 677,\n",
       " 'engaged': 678,\n",
       " 'drew': 679,\n",
       " 'ring': 680,\n",
       " 'company': 681,\n",
       " 'shook': 682,\n",
       " 'assistant': 683,\n",
       " 'full': 684,\n",
       " 'experience': 685,\n",
       " 'along': 686,\n",
       " 'claim': 687,\n",
       " 'silent': 688,\n",
       " 'reading': 689,\n",
       " 'professional': 690,\n",
       " 'den': 691,\n",
       " 'roylott': 692,\n",
       " 'ventilator': 693,\n",
       " 'excellent': 694,\n",
       " 'society': 695,\n",
       " 'chamber': 696,\n",
       " 'kindly': 697,\n",
       " 'walk': 698,\n",
       " 'itself': 699,\n",
       " 'almost': 700,\n",
       " 'someone': 701,\n",
       " 'show': 702,\n",
       " 'yours': 703,\n",
       " 'therefore': 704,\n",
       " 'continued': 705,\n",
       " 'character': 706,\n",
       " 'excuse': 707,\n",
       " 'result': 708,\n",
       " 'morrow': 709,\n",
       " 'deal': 710,\n",
       " 'shot': 711,\n",
       " \"'and\": 712,\n",
       " 'nor': 713,\n",
       " 'centre': 714,\n",
       " 'determined': 715,\n",
       " 'ross': 716,\n",
       " 'seem': 717,\n",
       " 'foot': 718,\n",
       " \"didn't\": 719,\n",
       " 'knowledge': 720,\n",
       " 'bank': 721,\n",
       " 'force': 722,\n",
       " 'pale': 723,\n",
       " \"man's\": 724,\n",
       " 'hotel': 725,\n",
       " 'wrong': 726,\n",
       " 'moran': 727,\n",
       " 'envelope': 728,\n",
       " 'horner': 729,\n",
       " 'pips': 730,\n",
       " 'results': 731,\n",
       " 'official': 732,\n",
       " 'fancy': 733,\n",
       " 'deduce': 734,\n",
       " 'lived': 735,\n",
       " 'inside': 736,\n",
       " 'caused': 737,\n",
       " 'double': 738,\n",
       " 'throwing': 739,\n",
       " 'example': 740,\n",
       " 'thick': 741,\n",
       " 'lying': 742,\n",
       " 'examined': 743,\n",
       " 'writing': 744,\n",
       " 'glass': 745,\n",
       " 'comes': 746,\n",
       " 'sit': 747,\n",
       " 'bad': 748,\n",
       " 'boots': 749,\n",
       " 'pushed': 750,\n",
       " 'absolute': 751,\n",
       " 'difficult': 752,\n",
       " 'mad': 753,\n",
       " 'pay': 754,\n",
       " 'monday': 755,\n",
       " 'wood': 756,\n",
       " 'expected': 757,\n",
       " 'probably': 758,\n",
       " 'arms': 759,\n",
       " 'streets': 760,\n",
       " 'nearly': 761,\n",
       " 'whatever': 762,\n",
       " 'taking': 763,\n",
       " 'cigar': 764,\n",
       " 'broke': 765,\n",
       " 'blood': 766,\n",
       " \"he's\": 767,\n",
       " 'change': 768,\n",
       " 'shoulder': 769,\n",
       " 'kind': 770,\n",
       " 'walking': 771,\n",
       " 'turning': 772,\n",
       " 'age': 773,\n",
       " 'common': 774,\n",
       " \"'you\": 775,\n",
       " 'died': 776,\n",
       " 'clay': 777,\n",
       " 'wooden': 778,\n",
       " 'building': 779,\n",
       " 'third': 780,\n",
       " 'amid': 781,\n",
       " 'early': 782,\n",
       " 'clearly': 783,\n",
       " 'merryweather': 784,\n",
       " 'presence': 785,\n",
       " 'darkness': 786,\n",
       " 'yellow': 787,\n",
       " 'clue': 788,\n",
       " 'surprised': 789,\n",
       " 'friends': 790,\n",
       " 'trap': 791,\n",
       " 'looks': 792,\n",
       " 'grew': 793,\n",
       " 'cleared': 794,\n",
       " 'opium': 795,\n",
       " 'lascar': 796,\n",
       " 'bradstreet': 797,\n",
       " 'bohemia': 798,\n",
       " 'orange': 799,\n",
       " 'lip': 800,\n",
       " 'noble': 801,\n",
       " 'complete': 802,\n",
       " 'master': 803,\n",
       " 'extraordinary': 804,\n",
       " 'following': 805,\n",
       " 'signs': 806,\n",
       " 'practice': 807,\n",
       " 'swiftly': 808,\n",
       " 'spoken': 809,\n",
       " 'dreadful': 810,\n",
       " \"can't\": 811,\n",
       " 'interested': 812,\n",
       " 'sheet': 813,\n",
       " 'post': 814,\n",
       " \"there's\": 815,\n",
       " 'trust': 816,\n",
       " 'passing': 817,\n",
       " 'subject': 818,\n",
       " 'send': 819,\n",
       " 'briony': 820,\n",
       " 'features': 821,\n",
       " 'lane': 822,\n",
       " 'dozen': 823,\n",
       " 'neighbourhood': 824,\n",
       " \"'the\": 825,\n",
       " 'running': 826,\n",
       " 'usual': 827,\n",
       " 'different': 828,\n",
       " 'action': 829,\n",
       " 'raise': 830,\n",
       " 'fine': 831,\n",
       " 'blow': 832,\n",
       " 'later': 833,\n",
       " 'arm': 834,\n",
       " 'questioning': 835,\n",
       " 'narrative': 836,\n",
       " 'heavily': 837,\n",
       " 'statement': 838,\n",
       " 'human': 839,\n",
       " 'everything': 840,\n",
       " 'jones': 841,\n",
       " 'scotland': 842,\n",
       " 'edge': 843,\n",
       " 'start': 844,\n",
       " 'alive': 845,\n",
       " 'plain': 846,\n",
       " 'traces': 847,\n",
       " 'public': 848,\n",
       " 'covered': 849,\n",
       " 'keeper': 850,\n",
       " 'innocent': 851,\n",
       " 'feeling': 852,\n",
       " 'terrible': 853,\n",
       " 'bent': 854,\n",
       " 'sometimes': 855,\n",
       " 'ryder': 856,\n",
       " 'stoke': 857,\n",
       " 'reasoning': 858,\n",
       " 'throw': 859,\n",
       " 'power': 860,\n",
       " 'memory': 861,\n",
       " 'keen': 862,\n",
       " 'press': 863,\n",
       " 'hot': 864,\n",
       " 'profession': 865,\n",
       " 'hall': 866,\n",
       " 'often': 867,\n",
       " 'quarter': 868,\n",
       " 'received': 869,\n",
       " 'scene': 870,\n",
       " 'precisely': 871,\n",
       " 'pair': 872,\n",
       " 'fifty': 873,\n",
       " 'rich': 874,\n",
       " 'thrown': 875,\n",
       " 'raised': 876,\n",
       " 'chin': 877,\n",
       " 'seat': 878,\n",
       " 'confess': 879,\n",
       " 'state': 880,\n",
       " 'attempt': 881,\n",
       " 'putting': 882,\n",
       " 'acquaintance': 883,\n",
       " 'thirty': 884,\n",
       " 'pretty': 885,\n",
       " 'inquiry': 886,\n",
       " 'investigation': 887,\n",
       " 'lock': 888,\n",
       " 'wall': 889,\n",
       " 'watch': 890,\n",
       " 'reach': 891,\n",
       " 'run': 892,\n",
       " 'wind': 893,\n",
       " \"'what\": 894,\n",
       " 'self': 895,\n",
       " 'contrary': 896,\n",
       " 'neither': 897,\n",
       " 'fall': 898,\n",
       " 'perfectly': 899,\n",
       " 'care': 900,\n",
       " 'wonder': 901,\n",
       " 'broken': 902,\n",
       " 'cross': 903,\n",
       " 'months': 904,\n",
       " 'wished': 905,\n",
       " 'saying': 906,\n",
       " 'thrust': 907,\n",
       " 'fortune': 908,\n",
       " 'cellar': 909,\n",
       " 'live': 910,\n",
       " 'american': 911,\n",
       " 'real': 912,\n",
       " 'exceedingly': 913,\n",
       " 'unfortunate': 914,\n",
       " 'middle': 915,\n",
       " 'beg': 916,\n",
       " 'knees': 917,\n",
       " 'fingers': 918,\n",
       " 'crop': 919,\n",
       " 'narrow': 920,\n",
       " 'corridor': 921,\n",
       " 'iron': 922,\n",
       " 'lantern': 923,\n",
       " 'lens': 924,\n",
       " 'weary': 925,\n",
       " 'connection': 926,\n",
       " 'assistance': 927,\n",
       " 'ceiling': 928,\n",
       " 'uncle': 929,\n",
       " 'pointed': 930,\n",
       " 'formed': 931,\n",
       " 'violence': 932,\n",
       " 'examination': 933,\n",
       " 'spite': 934,\n",
       " 'horsham': 935,\n",
       " 'ship': 936,\n",
       " 'whistle': 937,\n",
       " 'madam': 938,\n",
       " 'dressing': 939,\n",
       " 'christmas': 940,\n",
       " 'peterson': 941,\n",
       " 'henry': 942,\n",
       " 'hydraulic': 943,\n",
       " 'doran': 944,\n",
       " 'world': 945,\n",
       " 'soul': 946,\n",
       " 'books': 947,\n",
       " 'deeply': 948,\n",
       " 'study': 949,\n",
       " 'merely': 950,\n",
       " 'returning': 951,\n",
       " 'seized': 952,\n",
       " 'tall': 953,\n",
       " 'pass': 954,\n",
       " 'nervous': 955,\n",
       " 'mark': 956,\n",
       " 'easily': 957,\n",
       " 'houses': 958,\n",
       " 'carefully': 959,\n",
       " 'stairs': 960,\n",
       " 'upper': 961,\n",
       " 'suggestive': 962,\n",
       " 'wrist': 963,\n",
       " 'aware': 964,\n",
       " 'purpose': 965,\n",
       " 'visit': 966,\n",
       " 'opening': 967,\n",
       " 'hum': 968,\n",
       " 'bag': 969,\n",
       " 'handed': 970,\n",
       " 'certain': 971,\n",
       " 'vanished': 972,\n",
       " 'heads': 973,\n",
       " 'latter': 974,\n",
       " 'stepped': 975,\n",
       " 'ear': 976,\n",
       " 'lose': 977,\n",
       " 'twelve': 978,\n",
       " 'faced': 979,\n",
       " 'chain': 980,\n",
       " 'park': 981,\n",
       " 'general': 982,\n",
       " 'carry': 983,\n",
       " 'besides': 984,\n",
       " 'surely': 985,\n",
       " 'draw': 986,\n",
       " 'pavement': 987,\n",
       " 'evil': 988,\n",
       " 'sorry': 989,\n",
       " 'value': 990,\n",
       " 'conversation': 991,\n",
       " 'sutherland': 992,\n",
       " 'jabez': 993,\n",
       " 'remark': 994,\n",
       " 'column': 995,\n",
       " 'track': 996,\n",
       " 'coburg': 997,\n",
       " 'affair': 998,\n",
       " 'market': 999,\n",
       " \"'oh\": 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the index for the words\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input sequence\n",
    "input_sequences = []\n",
    "for line in text.split(\"\\n\"):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1534],\n",
       " [1, 1534, 4],\n",
       " [1, 1534, 4, 118],\n",
       " [1, 1534, 4, 118, 33],\n",
       " [3994, 3995],\n",
       " [3994, 3995, 3996],\n",
       " [228, 4],\n",
       " [228, 4, 1535],\n",
       " [6, 1038],\n",
       " [6, 1038, 7],\n",
       " [6, 1038, 7, 798],\n",
       " [1, 212],\n",
       " [1, 212, 381],\n",
       " [1, 212, 381, 542],\n",
       " [6, 103],\n",
       " [6, 103, 4],\n",
       " [6, 103, 4, 1797],\n",
       " [1, 579],\n",
       " [1, 579, 1161],\n",
       " [1, 579, 1161, 483],\n",
       " [1, 287],\n",
       " [1, 287, 799],\n",
       " [1, 287, 799, 730],\n",
       " [1, 56],\n",
       " [1, 56, 19],\n",
       " [1, 56, 19, 1],\n",
       " [1, 56, 19, 1, 1162],\n",
       " [1, 56, 19, 1, 1162, 800],\n",
       " [1, 514],\n",
       " [1, 514, 4],\n",
       " [1, 514, 4, 1],\n",
       " [1, 514, 4, 1, 457],\n",
       " [1, 514, 4, 1, 457, 1324],\n",
       " [1, 514],\n",
       " [1, 514, 4],\n",
       " [1, 514, 4, 1],\n",
       " [1, 514, 4, 1, 1536],\n",
       " [1, 514, 4, 1, 1536, 650],\n",
       " [1, 514],\n",
       " [1, 514, 4],\n",
       " [1, 514, 4, 1],\n",
       " [1, 514, 4, 1, 2805],\n",
       " [1, 514, 4, 1, 2805, 580],\n",
       " [1, 514],\n",
       " [1, 514, 4],\n",
       " [1, 514, 4, 1],\n",
       " [1, 514, 4, 1, 801],\n",
       " [1, 514, 4, 1, 801, 1163],\n",
       " [1, 514],\n",
       " [1, 514, 4],\n",
       " [1, 514, 4, 1],\n",
       " [1, 514, 4, 1, 2184],\n",
       " [1, 514, 4, 1, 2184, 2806],\n",
       " [1, 514],\n",
       " [1, 514, 4],\n",
       " [1, 514, 4, 1],\n",
       " [1, 514, 4, 1, 2807],\n",
       " [1, 514, 4, 1, 2807, 3997],\n",
       " [6, 1038],\n",
       " [6, 1038, 7],\n",
       " [6, 1038, 7, 798],\n",
       " [228, 4],\n",
       " [228, 4, 1535],\n",
       " [1325, 3998],\n",
       " [1325, 2185],\n",
       " [1325, 3999],\n",
       " [1325, 3],\n",
       " [5, 118],\n",
       " [5, 118, 33],\n",
       " [5, 118, 33, 38],\n",
       " [5, 118, 33, 38, 14],\n",
       " [5, 118, 33, 38, 14, 207],\n",
       " [5, 118, 33, 38, 14, 207, 1],\n",
       " [5, 118, 33, 38, 14, 207, 1, 213],\n",
       " [5, 118, 33, 38, 14, 207, 1, 213, 3],\n",
       " [5, 118, 33, 38, 14, 207, 1, 213, 3, 16],\n",
       " [5, 118, 33, 38, 14, 207, 1, 213, 3, 16, 1326],\n",
       " [5, 118, 33, 38, 14, 207, 1, 213, 3, 16, 1326, 109],\n",
       " [5, 118, 33, 38, 14, 207, 1, 213, 3, 16, 1326, 109, 35],\n",
       " [2808, 36],\n",
       " [2808, 36, 273],\n",
       " [2808, 36, 273, 106],\n",
       " [2808, 36, 273, 106, 94],\n",
       " [2808, 36, 273, 106, 94, 201],\n",
       " [2808, 36, 273, 106, 94, 201, 7],\n",
       " [2808, 36, 273, 106, 94, 201, 7, 13],\n",
       " [2808, 36, 273, 106, 94, 201, 7, 13, 148],\n",
       " [2808, 36, 273, 106, 94, 201, 7, 13, 148, 38],\n",
       " [2808, 36, 273, 106, 94, 201, 7, 13, 148, 38, 4000],\n",
       " [2808, 36, 273, 106, 94, 201, 7, 13, 148, 38, 4000, 2],\n",
       " [4001, 1],\n",
       " [4001, 1, 294],\n",
       " [4001, 1, 294, 4],\n",
       " [4001, 1, 294, 4, 36],\n",
       " [4001, 1, 294, 4, 36, 4002],\n",
       " [4001, 1, 294, 4, 36, 4002, 9],\n",
       " [4001, 1, 294, 4, 36, 4002, 9, 12],\n",
       " [4001, 1, 294, 4, 36, 4002, 9, 12, 24],\n",
       " [4001, 1, 294, 4, 36, 4002, 9, 12, 24, 8],\n",
       " [4001, 1, 294, 4, 36, 4002, 9, 12, 24, 8, 10],\n",
       " [4001, 1, 294, 4, 36, 4002, 9, 12, 24, 8, 10, 335],\n",
       " [4001, 1, 294, 4, 36, 4002, 9, 12, 24, 8, 10, 335, 106],\n",
       " [1798, 2186],\n",
       " [1798, 2186, 5],\n",
       " [1798, 2186, 5, 610],\n",
       " [1798, 2186, 5, 610, 22],\n",
       " [1798, 2186, 5, 610, 22, 581],\n",
       " [1798, 2186, 5, 610, 22, 581, 582],\n",
       " [1798, 2186, 5, 610, 22, 581, 582, 41],\n",
       " [1798, 2186, 5, 610, 22, 581, 582, 41, 4003],\n",
       " [1798, 2186, 5, 610, 22, 581, 582, 41, 4003, 2],\n",
       " [1798, 2186, 5, 610, 22, 581, 582, 41, 4003, 2, 8],\n",
       " [1798, 2186, 5, 610, 22, 581, 582, 41, 4003, 2, 8, 43],\n",
       " [1537, 47],\n",
       " [1537, 47, 4004],\n",
       " [1537, 47, 4004, 5],\n",
       " [1537, 47, 4004, 5, 13],\n",
       " [1537, 47, 4004, 5, 13, 458],\n",
       " [1537, 47, 4004, 5, 13, 458, 2187],\n",
       " [1537, 47, 4004, 5, 13, 458, 2187, 23],\n",
       " [1537, 47, 4004, 5, 13, 458, 2187, 23, 1799],\n",
       " [4005, 218],\n",
       " [4005, 218, 10],\n",
       " [4005, 218, 10, 12],\n",
       " [4005, 218, 10, 12, 3],\n",
       " [4005, 218, 10, 12, 3, 149],\n",
       " [4005, 218, 10, 12, 3, 149, 9],\n",
       " [4005, 218, 10, 12, 3, 149, 9, 1],\n",
       " [4005, 218, 10, 12, 3, 149, 9, 1, 154],\n",
       " [4005, 218, 10, 12, 3, 149, 9, 1, 154, 1327],\n",
       " [4005, 218, 10, 12, 3, 149, 9, 1, 154, 1327, 858],\n",
       " [4005, 218, 10, 12, 3, 149, 9, 1, 154, 1327, 858, 2],\n",
       " [1800, 583],\n",
       " [1800, 583, 8],\n",
       " [1800, 583, 8, 1],\n",
       " [1800, 583, 8, 1, 945],\n",
       " [1800, 583, 8, 1, 945, 57],\n",
       " [1800, 583, 8, 1, 945, 57, 155],\n",
       " [1800, 583, 8, 1, 945, 57, 155, 23],\n",
       " [1800, 583, 8, 1, 945, 57, 155, 23, 17],\n",
       " [1800, 583, 8, 1, 945, 57, 155, 23, 17, 6],\n",
       " [1800, 583, 8, 1, 945, 57, 155, 23, 17, 6, 2188],\n",
       " [1800, 583, 8, 1, 945, 57, 155, 23, 17, 6, 2188, 10],\n",
       " [1800, 583, 8, 1, 945, 57, 155, 23, 17, 6, 2188, 10, 54],\n",
       " [16, 611],\n",
       " [16, 611, 171],\n",
       " [16, 611, 171, 7],\n",
       " [16, 611, 171, 7, 6],\n",
       " [16, 611, 171, 7, 6, 1801],\n",
       " [16, 611, 171, 7, 6, 1801, 543],\n",
       " [16, 611, 171, 7, 6, 1801, 543, 10],\n",
       " [16, 611, 171, 7, 6, 1801, 543, 10, 119],\n",
       " [16, 611, 171, 7, 6, 1801, 543, 10, 119, 420],\n",
       " [16, 611, 171, 7, 6, 1801, 543, 10, 119, 420, 4],\n",
       " [16, 611, 171, 7, 6, 1801, 543, 10, 119, 420, 4, 1],\n",
       " [16, 611, 171, 7, 6, 1801, 543, 10, 119, 420, 4, 1, 4006],\n",
       " [4007, 281],\n",
       " [4007, 281, 19],\n",
       " [4007, 281, 19, 6],\n",
       " [4007, 281, 19, 6, 4008],\n",
       " [4007, 281, 19, 6, 4008, 2],\n",
       " [4007, 281, 19, 6, 4008, 2, 6],\n",
       " [4007, 281, 19, 6, 4008, 2, 6, 1802],\n",
       " [4007, 281, 19, 6, 4008, 2, 6, 1802, 72],\n",
       " [4007, 281, 19, 6, 4008, 2, 6, 1802, 72, 47],\n",
       " [4007, 281, 19, 6, 4008, 2, 6, 1802, 72, 47, 2809],\n",
       " [4007, 281, 19, 6, 4008, 2, 6, 1802, 72, 47, 2809, 369],\n",
       " [22, 1],\n",
       " [22, 1, 1803],\n",
       " [22, 1, 1803, 694],\n",
       " [22, 1, 1803, 694, 22],\n",
       " [22, 1, 1803, 694, 22, 1328],\n",
       " [22, 1, 1803, 694, 22, 1328, 1],\n",
       " [22, 1, 1803, 694, 22, 1328, 1, 1164],\n",
       " [22, 1, 1803, 694, 22, 1328, 1, 1164, 28],\n",
       " [22, 1, 1803, 694, 22, 1328, 1, 1164, 28, 2810],\n",
       " [22, 1, 1803, 694, 22, 1328, 1, 1164, 28, 2810, 2811],\n",
       " [2, 2189],\n",
       " [2, 2189, 23],\n",
       " [2, 2189, 23, 22],\n",
       " [2, 2189, 23, 22, 1],\n",
       " [2, 2189, 23, 22, 1, 1804],\n",
       " [2, 2189, 23, 22, 1, 1804, 1329],\n",
       " [2, 2189, 23, 22, 1, 1804, 1329, 5],\n",
       " [2, 2189, 23, 22, 1, 1804, 1329, 5, 2812],\n",
       " [2, 2189, 23, 22, 1, 1804, 1329, 5, 2812, 111],\n",
       " [2, 2189, 23, 22, 1, 1804, 1329, 5, 2812, 111, 4009],\n",
       " [58, 13],\n",
       " [58, 13, 125],\n",
       " [58, 13, 125, 1330],\n",
       " [58, 13, 125, 1330, 2],\n",
       " [58, 13, 125, 1330, 2, 4010],\n",
       " [58, 13, 125, 1330, 2, 4010, 2813],\n",
       " [58, 13, 125, 1330, 2, 4010, 2813, 4011],\n",
       " [58, 13, 125, 1330, 2, 4010, 2813, 4011, 12],\n",
       " [58, 13, 125, 1330, 2, 4010, 2813, 4011, 12, 5],\n",
       " [1805, 6],\n",
       " [1805, 6, 4012],\n",
       " [1805, 6, 4012, 2814],\n",
       " [1805, 6, 4012, 2814, 20],\n",
       " [1805, 6, 4012, 2814, 20, 105],\n",
       " [1805, 6, 4012, 2814, 20, 105, 859],\n",
       " [1805, 6, 4012, 2814, 20, 105, 859, 6],\n",
       " [1805, 6, 4012, 2814, 20, 105, 859, 6, 214],\n",
       " [1805, 6, 4012, 2814, 20, 105, 859, 6, 214, 30],\n",
       " [1805, 6, 4012, 2814, 20, 105, 859, 6, 214, 30, 41],\n",
       " [1805, 6, 4012, 2814, 20, 105, 859, 6, 214, 30, 41, 13],\n",
       " [4013, 731],\n",
       " [4013, 731, 4014],\n",
       " [4013, 731, 4014, 7],\n",
       " [4013, 731, 4014, 7, 6],\n",
       " [4013, 731, 4014, 7, 6, 4015],\n",
       " [4013, 731, 4014, 7, 6, 4015, 2815],\n",
       " [4013, 731, 4014, 7, 6, 4015, 2815, 73],\n",
       " [4013, 731, 4014, 7, 6, 4015, 2815, 73, 6],\n",
       " [4013, 731, 4014, 7, 6, 4015, 2815, 73, 6, 2190],\n",
       " [4013, 731, 4014, 7, 6, 4015, 2815, 73, 6, 2190, 7],\n",
       " [4013, 731, 4014, 7, 6, 4015, 2815, 73, 6, 2190, 7, 43],\n",
       " [4013, 731, 4014, 7, 6, 4015, 2815, 73, 6, 2190, 7, 43, 4],\n",
       " [13, 125],\n",
       " [13, 125, 436],\n",
       " [13, 125, 436, 860],\n",
       " [13, 125, 436, 860, 4016],\n",
       " [13, 125, 436, 860, 4016, 54],\n",
       " [13, 125, 436, 860, 4016, 54, 24],\n",
       " [13, 125, 436, 860, 4016, 54, 24, 25],\n",
       " [13, 125, 436, 860, 4016, 54, 24, 25, 81],\n",
       " [13, 125, 436, 860, 4016, 54, 24, 25, 81, 4017],\n",
       " [13, 125, 436, 860, 4016, 54, 24, 25, 81, 4017, 90],\n",
       " [13, 125, 436, 860, 4016, 54, 24, 25, 81, 4017, 90, 6],\n",
       " [13, 125, 436, 860, 4016, 54, 24, 25, 81, 4017, 90, 6, 351],\n",
       " [1798, 7],\n",
       " [1798, 7, 6],\n",
       " [1798, 7, 6, 437],\n",
       " [1798, 7, 6, 437, 111],\n",
       " [1798, 7, 6, 437, 111, 17],\n",
       " [1798, 7, 6, 437, 111, 17, 13],\n",
       " [1798, 7, 6, 437, 111, 17, 13, 2],\n",
       " [1798, 7, 6, 437, 111, 17, 13, 2, 139],\n",
       " [1798, 7, 6, 437, 111, 17, 13, 2, 139, 29],\n",
       " [1798, 7, 6, 437, 111, 17, 13, 2, 139, 29, 12],\n",
       " [1798, 7, 6, 437, 111, 17, 13, 2, 139, 29, 12, 23],\n",
       " [1798, 7, 6, 437, 111, 17, 13, 2, 139, 29, 12, 23, 43],\n",
       " [1798, 7, 6, 437, 111, 17, 13, 2, 139, 29, 12, 23, 43, 213],\n",
       " [1798, 7, 6, 437, 111, 17, 13, 2, 139, 29, 12, 23, 43, 213, 5],\n",
       " [35, 2],\n",
       " [35, 2, 8],\n",
       " [35, 2, 8, 213],\n",
       " [35, 2, 8, 213, 12],\n",
       " [35, 2, 8, 213, 12, 1],\n",
       " [35, 2, 8, 213, 12, 1, 438],\n",
       " [35, 2, 8, 213, 12, 1, 438, 581],\n",
       " [35, 2, 8, 213, 12, 1, 438, 581, 582],\n",
       " [35, 2, 8, 213, 12, 1, 438, 581, 582, 4],\n",
       " [35, 2, 8, 213, 12, 1, 438, 581, 582, 4, 4018],\n",
       " [35, 2, 8, 213, 12, 1, 438, 581, 582, 4, 4018, 2],\n",
       " [4019, 861],\n",
       " [3, 18],\n",
       " [3, 18, 155],\n",
       " [3, 18, 155, 63],\n",
       " [3, 18, 155, 63, 4],\n",
       " [3, 18, 155, 63, 4, 33],\n",
       " [3, 18, 155, 63, 4, 33, 1331],\n",
       " [3, 18, 155, 63, 4, 33, 1331, 15],\n",
       " [3, 18, 155, 63, 4, 33, 1331, 15, 352],\n",
       " [3, 18, 155, 63, 4, 33, 1331, 15, 352, 18],\n",
       " [3, 18, 155, 63, 4, 33, 1331, 15, 352, 18, 2816],\n",
       " [3, 18, 155, 63, 4, 33, 1331, 15, 352, 18, 2816, 74],\n",
       " [3, 18, 155, 63, 4, 33, 1331, 15, 352, 18, 2816, 74, 123],\n",
       " [28, 382],\n",
       " [28, 382, 94],\n",
       " [28, 382, 94, 15],\n",
       " [28, 382, 94, 15, 125],\n",
       " [28, 382, 94, 15, 125, 802],\n",
       " [28, 382, 94, 15, 125, 802, 2191],\n",
       " [28, 382, 94, 15, 125, 802, 2191, 2],\n",
       " [28, 382, 94, 15, 125, 802, 2191, 2, 1],\n",
       " [28, 382, 94, 15, 125, 802, 2191, 2, 1, 219],\n",
       " [28, 382, 94, 15, 125, 802, 2191, 2, 1, 219, 4020],\n",
       " [2192, 20],\n",
       " [2192, 20, 1538],\n",
       " [2192, 20, 1538, 55],\n",
       " [2192, 20, 1538, 55, 2817],\n",
       " [2192, 20, 1538, 55, 2817, 1],\n",
       " [2192, 20, 1538, 55, 2817, 1, 56],\n",
       " [2192, 20, 1538, 55, 2817, 1, 56, 64],\n",
       " [2192, 20, 1538, 55, 2817, 1, 56, 64, 150],\n",
       " [2192, 20, 1538, 55, 2817, 1, 56, 64, 150, 2193],\n",
       " [2192, 20, 1538, 55, 2817, 1, 56, 64, 150, 2193, 171],\n",
       " [2192, 20, 1538, 55, 2817, 1, 56, 64, 150, 2193, 171, 803],\n",
       " [4, 13],\n",
       " [4, 13, 125],\n",
       " [4, 13, 125, 4021],\n",
       " [4, 13, 125, 4021, 47],\n",
       " [4, 13, 125, 4021, 47, 2194],\n",
       " [4, 13, 125, 4021, 47, 2194, 5],\n",
       " [4, 13, 125, 4021, 47, 2194, 5, 4022],\n",
       " [4, 13, 125, 4021, 47, 2194, 5, 4022, 41],\n",
       " [4, 13, 125, 4021, 47, 2194, 5, 4022, 41, 15],\n",
       " [4, 13, 125, 4021, 47, 2194, 5, 4022, 41, 15, 383],\n",
       " [172, 33],\n",
       " [172, 33, 64],\n",
       " [172, 33, 64, 4023],\n",
       " [172, 33, 64, 4023, 145],\n",
       " [172, 33, 64, 4023, 145, 1332],\n",
       " [172, 33, 64, 4023, 145, 1332, 4],\n",
       " [172, 33, 64, 4023, 145, 1332, 4, 695],\n",
       " [172, 33, 64, 4023, 145, 1332, 4, 695, 19],\n",
       " [172, 33, 64, 4023, 145, 1332, 4, 695, 19, 13],\n",
       " [172, 33, 64, 4023, 145, 1332, 4, 695, 19, 13, 294],\n",
       " [1806, 946],\n",
       " [1806, 946, 544],\n",
       " [1806, 946, 544, 7],\n",
       " [1806, 946, 544, 7, 70],\n",
       " [1806, 946, 544, 7, 70, 1165],\n",
       " [1806, 946, 544, 7, 70, 1165, 7],\n",
       " [1806, 946, 544, 7, 70, 1165, 7, 268],\n",
       " [1806, 946, 544, 7, 70, 1165, 7, 268, 135],\n",
       " [1806, 946, 544, 7, 70, 1165, 7, 268, 135, 1807],\n",
       " [1806, 946, 544, 7, 70, 1165, 7, 268, 135, 1807, 301],\n",
       " [13, 165],\n",
       " [13, 165, 947],\n",
       " [13, 165, 947, 2],\n",
       " [13, 165, 947, 2, 4024],\n",
       " [13, 165, 947, 2, 4024, 28],\n",
       " [13, 165, 947, 2, 4024, 28, 421],\n",
       " [13, 165, 947, 2, 4024, 28, 421, 5],\n",
       " [13, 165, 947, 2, 4024, 28, 421, 5, 421],\n",
       " [13, 165, 947, 2, 4024, 28, 421, 5, 421, 204],\n",
       " [13, 165, 947, 2, 4024, 28, 421, 5, 421, 204, 2195],\n",
       " [13, 165, 947, 2, 4024, 28, 421, 5, 421, 204, 2195, 2],\n",
       " [4025, 1],\n",
       " [4025, 1, 4026],\n",
       " [4025, 1, 4026, 4],\n",
       " [4025, 1, 4026, 4, 1],\n",
       " [4025, 1, 4026, 4, 1, 1539],\n",
       " [4025, 1, 4026, 4, 1, 1539, 2],\n",
       " [4025, 1, 4026, 4, 1, 1539, 2, 1],\n",
       " [4025, 1, 4026, 4, 1, 1539, 2, 1, 1333],\n",
       " [4025, 1, 4026, 4, 1, 1539, 2, 1, 1333, 1540],\n",
       " [4025, 1, 4026, 4, 1, 1539, 2, 1, 1333, 1540, 4],\n",
       " [4025, 1, 4026, 4, 1, 1539, 2, 1, 1333, 1540, 4, 13],\n",
       " [125, 862],\n",
       " [125, 862, 437],\n",
       " [125, 862, 437, 10],\n",
       " [125, 862, 437, 10, 12],\n",
       " [125, 862, 437, 10, 12, 156],\n",
       " [125, 862, 437, 10, 12, 156, 17],\n",
       " [125, 862, 437, 10, 12, 156, 17, 190],\n",
       " [125, 862, 437, 10, 12, 156, 17, 190, 948],\n",
       " [125, 862, 437, 10, 12, 156, 17, 190, 948, 2196],\n",
       " [125, 862, 437, 10, 12, 156, 17, 190, 948, 2196, 48],\n",
       " [125, 862, 437, 10, 12, 156, 17, 190, 948, 2196, 48, 1],\n",
       " [125, 862, 437, 10, 12, 156, 17, 190, 948, 2196, 48, 1, 949],\n",
       " [4, 370],\n",
       " [4, 370, 2],\n",
       " [4, 370, 2, 4027],\n",
       " [4, 370, 2, 4027, 13],\n",
       " [4, 370, 2, 4027, 13, 1166],\n",
       " [4, 370, 2, 4027, 13, 1166, 4028],\n",
       " [4, 370, 2, 4027, 13, 1166, 4028, 2],\n",
       " [4, 370, 2, 4027, 13, 1166, 4028, 2, 804],\n",
       " [4, 370, 2, 4027, 13, 1166, 4028, 2, 804, 1541],\n",
       " [4, 1334],\n",
       " [4, 1334, 7],\n",
       " [4, 1334, 7, 805],\n",
       " [4, 1334, 7, 805, 52],\n",
       " [4, 1334, 7, 805, 52, 162],\n",
       " [4, 1334, 7, 805, 52, 162, 2197],\n",
       " [4, 1334, 7, 805, 52, 162, 2197, 2],\n",
       " [4, 1334, 7, 805, 52, 162, 2197, 2, 1167],\n",
       " [4, 1334, 7, 805, 52, 162, 2197, 2, 1167, 55],\n",
       " [4, 1334, 7, 805, 52, 162, 2197, 2, 1167, 55, 162],\n",
       " [2198, 20],\n",
       " [2198, 20, 18],\n",
       " [2198, 20, 18, 39],\n",
       " [2198, 20, 18, 39, 2199],\n",
       " [2198, 20, 18, 39, 2199, 17],\n",
       " [2198, 20, 18, 39, 2199, 17, 2818],\n",
       " [2198, 20, 18, 39, 2199, 17, 2818, 48],\n",
       " [2198, 20, 18, 39, 2199, 17, 2818, 48, 1],\n",
       " [2198, 20, 18, 39, 2199, 17, 2818, 48, 1, 732],\n",
       " [240, 28],\n",
       " [240, 28, 84],\n",
       " [240, 28, 84, 5],\n",
       " [240, 28, 84, 5, 84],\n",
       " [240, 28, 84, 5, 84, 3],\n",
       " [240, 28, 84, 5, 84, 3, 109],\n",
       " [240, 28, 84, 5, 84, 3, 109, 59],\n",
       " [240, 28, 84, 5, 84, 3, 109, 59, 1039],\n",
       " [240, 28, 84, 5, 84, 3, 109, 59, 1039, 515],\n",
       " [240, 28, 84, 5, 84, 3, 109, 59, 1039, 515, 4],\n",
       " [240, 28, 84, 5, 84, 3, 109, 59, 1039, 515, 4, 13],\n",
       " [240, 28, 84, 5, 84, 3, 109, 59, 1039, 515, 4, 13, 2819],\n",
       " [4, 13],\n",
       " [4, 13, 4029],\n",
       " [4, 13, 4029, 5],\n",
       " [4, 13, 4029, 5, 4030],\n",
       " [4, 13, 4029, 5, 4030, 7],\n",
       " [4, 13, 4029, 5, 4030, 7, 1],\n",
       " [4, 13, 4029, 5, 4030, 7, 1, 103],\n",
       " [4, 13, 4029, 5, 4030, 7, 1, 103, 4],\n",
       " [4, 13, 4029, 5, 4030, 7, 1, 103, 4, 1],\n",
       " [4, 13, 4029, 5, 4030, 7, 1, 103, 4, 1, 4031],\n",
       " [4, 13, 4029, 5, 4030, 7, 1, 103, 4, 1, 4031, 1168],\n",
       " [4, 13, 4029, 5, 4030, 7, 1, 103, 4, 1, 4031, 1168, 4],\n",
       " [4, 13, 4029, 5, 4030, 7, 1, 103, 4, 1, 4031, 1168, 4, 13],\n",
       " [1167, 55],\n",
       " [1167, 55, 4],\n",
       " [1167, 55, 4, 1],\n",
       " [1167, 55, 4, 1, 312],\n",
       " [1167, 55, 4, 1, 312, 1542],\n",
       " [1167, 55, 4, 1, 312, 1542, 4],\n",
       " [1167, 55, 4, 1, 312, 1542, 4, 1],\n",
       " [1167, 55, 4, 1, 312, 1542, 4, 1, 4032],\n",
       " [1167, 55, 4, 1, 312, 1542, 4, 1, 4032, 4033],\n",
       " [1167, 55, 4, 1, 312, 1542, 4, 1, 4032, 4033, 21],\n",
       " [4034, 2],\n",
       " [4034, 2, 545],\n",
       " [4034, 2, 545, 4],\n",
       " [4034, 2, 545, 4, 1],\n",
       " [4034, 2, 545, 4, 1, 2200],\n",
       " [4034, 2, 545, 4, 1, 2200, 20],\n",
       " [4034, 2, 545, 4, 1, 2200, 20, 10],\n",
       " [4034, 2, 545, 4, 1, 2200, 20, 10, 18],\n",
       " [4034, 2, 545, 4, 1, 2200, 20, 10, 18, 2820],\n",
       " [4034, 2, 545, 4, 1, 2200, 20, 10, 18, 2820, 34],\n",
       " [4035, 2],\n",
       " [4035, 2, 4036],\n",
       " [4035, 2, 4036, 22],\n",
       " [4035, 2, 4036, 22, 1],\n",
       " [4035, 2, 4036, 22, 1, 2201],\n",
       " [4035, 2, 4036, 22, 1, 2201, 371],\n",
       " [4035, 2, 4036, 22, 1, 2201, 371, 4],\n",
       " [4035, 2, 4036, 22, 1, 2201, 371, 4, 2821],\n",
       " [1169, 152],\n",
       " [1169, 152, 806],\n",
       " [1169, 152, 806, 4],\n",
       " [1169, 152, 806, 4, 13],\n",
       " [1169, 152, 806, 4, 13, 4037],\n",
       " [1169, 152, 806, 4, 13, 4037, 124],\n",
       " [1169, 152, 806, 4, 13, 4037, 124, 20],\n",
       " [1169, 152, 806, 4, 13, 4037, 124, 20, 3],\n",
       " [1169, 152, 806, 4, 13, 4037, 124, 20, 3, 950],\n",
       " [1169, 152, 806, 4, 13, 4037, 124, 20, 3, 950, 4038],\n",
       " [19, 41],\n",
       " [19, 41, 1],\n",
       " [19, 41, 1, 4039],\n",
       " [19, 41, 1, 4039, 4],\n",
       " [19, 41, 1, 4039, 4, 1],\n",
       " [19, 41, 1, 4039, 4, 1, 2822],\n",
       " [19, 41, 1, 4039, 4, 1, 2822, 863],\n",
       " [19, 41, 1, 4039, 4, 1, 2822, 863, 3],\n",
       " [19, 41, 1, 4039, 4, 1, 2822, 863, 3, 220],\n",
       " [19, 41, 1, 4039, 4, 1, 2822, 863, 3, 220, 63],\n",
       " [19, 41, 1, 4039, 4, 1, 2822, 863, 3, 220, 63, 4],\n",
       " [19, 41, 1, 4039, 4, 1, 2822, 863, 3, 220, 63, 4, 15],\n",
       " [19, 41, 1, 4039, 4, 1, 2822, 863, 3, 220, 63, 4, 15, 2202],\n",
       " [177, 2],\n",
       " [177, 2, 313],\n",
       " [43, 121],\n",
       " [43, 121, 9],\n",
       " [43, 121, 9, 12],\n",
       " [43, 121, 9, 12, 40],\n",
       " [43, 121, 9, 12, 40, 1],\n",
       " [43, 121, 9, 12, 40, 1, 2823],\n",
       " [43, 121, 9, 12, 40, 1, 2823, 4],\n",
       " [43, 121, 9, 12, 40, 1, 2823, 4, 1335],\n",
       " [43, 121, 9, 12, 40, 1, 2823, 4, 1335, 4040],\n",
       " [43, 121, 9, 12, 40, 1, 2823, 4, 1335, 4040, 3],\n",
       " [43, 121, 9, 12, 40, 1, 2823, 4, 1335, 4040, 3, 12],\n",
       " [43, 121, 9, 12, 40, 1, 2823, 4, 1335, 4040, 3, 12, 951],\n",
       " [28, 6],\n",
       " [28, 6, 1336],\n",
       " [28, 6, 1336, 5],\n",
       " [28, 6, 1336, 5, 6],\n",
       " [28, 6, 1336, 5, 6, 1170],\n",
       " [28, 6, 1336, 5, 6, 1170, 22],\n",
       " [28, 6, 1336, 5, 6, 1170, 22, 3],\n",
       " [28, 6, 1336, 5, 6, 1170, 22, 3, 18],\n",
       " [28, 6, 1336, 5, 6, 1170, 22, 3, 18, 68],\n",
       " [28, 6, 1336, 5, 6, 1170, 22, 3, 18, 68, 314],\n",
       " [28, 6, 1336, 5, 6, 1170, 22, 3, 18, 68, 314, 5],\n",
       " [28, 6, 1336, 5, 6, 1170, 22, 3, 18, 68, 314, 5, 2203],\n",
       " [807, 53],\n",
       " [807, 53, 15],\n",
       " [807, 53, 15, 107],\n",
       " [807, 53, 15, 107, 459],\n",
       " [807, 53, 15, 107, 459, 26],\n",
       " [807, 53, 15, 107, 459, 26, 138],\n",
       " [807, 53, 15, 107, 459, 26, 138, 268],\n",
       " [807, 53, 15, 107, 459, 26, 138, 268, 135],\n",
       " [807, 53, 15, 107, 459, 26, 138, 268, 135, 17],\n",
       " [807, 53, 15, 107, 459, 26, 138, 268, 135, 17, 3],\n",
       " [807, 53, 15, 107, 459, 26, 138, 268, 135, 17, 3, 324],\n",
       " [807, 53, 15, 107, 459, 26, 138, 268, 135, 17, 3, 324, 1],\n",
       " [71, 1808],\n",
       " [71, 1808, 108],\n",
       " [71, 1808, 108, 20],\n",
       " [71, 1808, 108, 20, 89],\n",
       " [71, 1808, 108, 20, 89, 207],\n",
       " [71, 1808, 108, 20, 89, 207, 25],\n",
       " [71, 1808, 108, 20, 89, 207, 25, 1809],\n",
       " [71, 1808, 108, 20, 89, 207, 25, 1809, 7],\n",
       " [71, 1808, 108, 20, 89, 207, 25, 1809, 7, 15],\n",
       " [71, 1808, 108, 20, 89, 207, 25, 1809, 7, 15, 218],\n",
       " [71, 1808, 108, 20, 89, 207, 25, 1809, 7, 15, 218, 19],\n",
       " [15, 2824],\n",
       " [15, 2824, 2],\n",
       " [15, 2824, 2, 19],\n",
       " [15, 2824, 2, 19, 1],\n",
       " [15, 2824, 2, 19, 1, 305],\n",
       " [15, 2824, 2, 19, 1, 305, 2204],\n",
       " [15, 2824, 2, 19, 1, 305, 2204, 4],\n",
       " [15, 2824, 2, 19, 1, 305, 2204, 4, 1],\n",
       " [15, 2824, 2, 19, 1, 305, 2204, 4, 1, 949],\n",
       " [15, 2824, 2, 19, 1, 305, 2204, 4, 1, 949, 7],\n",
       " [15, 2824, 2, 19, 1, 305, 2204, 4, 1, 949, 7, 2205],\n",
       " [15, 2824, 2, 19, 1, 305, 2204, 4, 1, 949, 7, 2205, 3],\n",
       " [15, 2824, 2, 19, 1, 305, 2204, 4, 1, 949, 7, 2205, 3, 12],\n",
       " [952, 19],\n",
       " [952, 19, 6],\n",
       " [952, 19, 6, 862],\n",
       " [952, 19, 6, 862, 1810],\n",
       " [952, 19, 6, 862, 1810, 5],\n",
       " [952, 19, 6, 862, 1810, 5, 67],\n",
       " [952, 19, 6, 862, 1810, 5, 67, 33],\n",
       " [952, 19, 6, 862, 1810, 5, 67, 33, 208],\n",
       " [952, 19, 6, 862, 1810, 5, 67, 33, 208, 2],\n",
       " [952, 19, 6, 862, 1810, 5, 67, 33, 208, 2, 5],\n",
       " [952, 19, 6, 862, 1810, 5, 67, 33, 208, 2, 5, 79],\n",
       " [952, 19, 6, 862, 1810, 5, 67, 33, 208, 2, 5, 79, 96],\n",
       " [952, 19, 6, 862, 1810, 5, 67, 33, 208, 2, 5, 79, 96, 10],\n",
       " [952, 19, 6, 862, 1810, 5, 67, 33, 208, 2, 5, 79, 96, 10, 12],\n",
       " [2825, 13],\n",
       " [2825, 13, 804],\n",
       " [2825, 13, 804, 1541],\n",
       " [2825, 13, 804, 1541, 13],\n",
       " [2825, 13, 804, 1541, 13, 422],\n",
       " [2825, 13, 804, 1541, 13, 422, 47],\n",
       " [2825, 13, 804, 1541, 13, 422, 47, 2826],\n",
       " [2825, 13, 804, 1541, 13, 422, 47, 2826, 612],\n",
       " [2, 178],\n",
       " [2, 178, 17],\n",
       " [2, 178, 17, 3],\n",
       " [2, 178, 17, 3, 241],\n",
       " [2, 178, 17, 3, 241, 55],\n",
       " [2, 178, 17, 3, 241, 55, 3],\n",
       " [2, 178, 17, 3, 241, 55, 3, 158],\n",
       " [2, 178, 17, 3, 241, 55, 3, 158, 13],\n",
       " [2, 178, 17, 3, 241, 55, 3, 158, 13, 953],\n",
       " [2, 178, 17, 3, 241, 55, 3, 158, 13, 953, 1171],\n",
       " [2, 178, 17, 3, 241, 55, 3, 158, 13, 953, 1171, 613],\n",
       " [2, 178, 17, 3, 241, 55, 3, 158, 13, 953, 1171, 613, 954],\n",
       " [2, 178, 17, 3, 241, 55, 3, 158, 13, 953, 1171, 613, 954, 651],\n",
       " [2, 178, 17, 3, 241, 55, 3, 158, 13, 953, 1171, 613, 954, 651, 7],\n",
       " [6, 305],\n",
       " [6, 305, 4041],\n",
       " [6, 305, 4041, 232],\n",
       " [6, 305, 4041, 232, 1],\n",
       " [6, 305, 4041, 232, 1, 2827],\n",
       " [6, 305, 4041, 232, 1, 2827, 10],\n",
       " [6, 305, 4041, 232, 1, 2827, 10, 12],\n",
       " [6, 305, 4041, 232, 1, 2827, 10, 12, 2206],\n",
       " [6, 305, 4041, 232, 1, 2827, 10, 12, 2206, 1],\n",
       " [6, 305, 4041, 232, 1, 2827, 10, 12, 2206, 1, 91],\n",
       " [6, 305, 4041, 232, 1, 2827, 10, 12, 2206, 1, 91, 808],\n",
       " [2207, 19],\n",
       " [2207, 19, 13],\n",
       " [2207, 19, 13, 179],\n",
       " [2207, 19, 13, 179, 1040],\n",
       " [2207, 19, 13, 179, 1040, 30],\n",
       " [2207, 19, 13, 179, 1040, 30, 13],\n",
       " [2207, 19, 13, 179, 1040, 30, 13, 1811],\n",
       " [2207, 19, 13, 179, 1040, 30, 13, 1811, 2],\n",
       " [2207, 19, 13, 179, 1040, 30, 13, 1811, 2, 13],\n",
       " [2207, 19, 13, 179, 1040, 30, 13, 1811, 2, 13, 186],\n",
       " [2207, 19, 13, 179, 1040, 30, 13, 1811, 2, 13, 186, 4042],\n",
       " [248, 35],\n",
       " [248, 35, 5],\n",
       " [248, 35, 5, 26],\n",
       " [248, 35, 5, 26, 64],\n",
       " [248, 35, 5, 26, 64, 220],\n",
       " [248, 35, 5, 26, 64, 220, 13],\n",
       " [248, 35, 5, 26, 64, 220, 13, 145],\n",
       " [248, 35, 5, 26, 64, 220, 13, 145, 2828],\n",
       " [248, 35, 5, 26, 64, 220, 13, 145, 2828, 2],\n",
       " [248, 35, 5, 26, 64, 220, 13, 145, 2828, 2, 1337],\n",
       " [248, 35, 5, 26, 64, 220, 13, 145, 2828, 2, 1337, 13],\n",
       " [248, 35, 5, 26, 64, 220, 13, 145, 2828, 2, 1337, 13, 2829],\n",
       " [2, 439],\n",
       " [2, 439, 282],\n",
       " [2, 439, 282, 134],\n",
       " [2, 439, 282, 134, 125],\n",
       " [2, 439, 282, 134, 125, 407],\n",
       " [2, 439, 282, 134, 125, 407, 10],\n",
       " [2, 439, 282, 134, 125, 407, 10, 12],\n",
       " [2, 439, 282, 134, 125, 407, 10, 12, 21],\n",
       " [2, 439, 282, 134, 125, 407, 10, 12, 21, 224],\n",
       " [2, 439, 282, 134, 125, 407, 10, 12, 21, 224, 208],\n",
       " [2, 439, 282, 134, 125, 407, 10, 12, 21, 224, 208, 10],\n",
       " [2, 439, 282, 134, 125, 407, 10, 12, 21, 224, 208, 10, 18],\n",
       " [2, 439, 282, 134, 125, 407, 10, 12, 21, 224, 208, 10, 18, 1812],\n",
       " [52, 4],\n",
       " [52, 4, 13],\n",
       " [52, 4, 13, 1539],\n",
       " [52, 4, 13, 1539, 4043],\n",
       " [52, 4, 13, 1539, 4043, 2830],\n",
       " [52, 4, 13, 1539, 4043, 2830, 2],\n",
       " [52, 4, 13, 1539, 4043, 2830, 2, 12],\n",
       " [52, 4, 13, 1539, 4043, 2830, 2, 12, 864],\n",
       " [52, 4, 13, 1539, 4043, 2830, 2, 12, 864, 30],\n",
       " [52, 4, 13, 1539, 4043, 2830, 2, 12, 864, 30, 1],\n",
       " [52, 4, 13, 1539, 4043, 2830, 2, 12, 864, 30, 1, 1543],\n",
       " [52, 4, 13, 1539, 4043, 2830, 2, 12, 864, 30, 1, 1543, 4],\n",
       " [52, 4, 13, 1539, 4043, 2830, 2, 12, 864, 30, 1, 1543, 4, 59],\n",
       " [52, 4, 13, 1539, 4043, 2830, 2, 12, 864, 30, 1, 1543, 4, 59, 325],\n",
       " [584, 3],\n",
       " [584, 3, 1813],\n",
       " [584, 3, 1813, 1],\n",
       " [584, 3, 1813, 1, 384],\n",
       " [584, 3, 1813, 1, 384, 2],\n",
       " [584, 3, 1813, 1, 384, 2, 12],\n",
       " [584, 3, 1813, 1, 384, 2, 12, 652],\n",
       " [584, 3, 1813, 1, 384, 2, 12, 652, 55],\n",
       " [584, 3, 1813, 1, 384, 2, 12, 652, 55, 5],\n",
       " [584, 3, 1813, 1, 384, 2, 12, 652, 55, 5, 1],\n",
       " [584, 3, 1813, 1, 384, 2, 12, 652, 55, 5, 1, 696],\n",
       " [584, 3, 1813, 1, 384, 2, 12, 652, 55, 5, 1, 696, 20],\n",
       " [584, 3, 1813, 1, 384, 2, 12, 652, 55, 5, 1, 696, 20, 18],\n",
       " [1814, 39],\n",
       " [1814, 39, 7],\n",
       " [1814, 39, 7, 372],\n",
       " [1814, 39, 7, 372, 15],\n",
       " [1814, 39, 7, 372, 15, 125],\n",
       " [13, 439],\n",
       " [13, 439, 12],\n",
       " [13, 439, 12, 24],\n",
       " [13, 439, 12, 24, 4044],\n",
       " [13, 439, 12, 24, 4044, 9],\n",
       " [13, 439, 12, 24, 4044, 9, 1326],\n",
       " [13, 439, 12, 24, 4044, 9, 1326, 12],\n",
       " [13, 439, 12, 24, 4044, 9, 1326, 12, 23],\n",
       " [13, 439, 12, 24, 4044, 9, 1326, 12, 23, 10],\n",
       " [13, 439, 12, 24, 4044, 9, 1326, 12, 23, 10, 12],\n",
       " [13, 439, 12, 24, 4044, 9, 1326, 12, 23, 10, 12, 653],\n",
       " [13, 439, 12, 24, 4044, 9, 1326, 12, 23, 10, 12, 653, 3],\n",
       " [13, 439, 12, 24, 4044, 9, 1326, 12, 23, 10, 12, 653, 3, 88],\n",
       " [5, 67],\n",
       " [5, 67, 26],\n",
       " [5, 67, 26, 19],\n",
       " [5, 67, 26, 19, 256],\n",
       " [5, 67, 26, 19, 256, 6],\n",
       " [5, 67, 26, 19, 256, 6, 336],\n",
       " [5, 67, 26, 19, 256, 6, 336, 809],\n",
       " [5, 67, 26, 19, 256, 6, 336, 809, 23],\n",
       " [5, 67, 26, 19, 256, 6, 336, 809, 23, 19],\n",
       " [5, 67, 26, 19, 256, 6, 336, 809, 23, 19, 6],\n",
       " [5, 67, 26, 19, 256, 6, 336, 809, 23, 19, 6, 697],\n",
       " [5, 67, 26, 19, 256, 6, 336, 809, 23, 19, 6, 697, 408],\n",
       " [5, 67, 26, 19, 256, 6, 336, 809, 23, 19, 6, 697, 408, 10],\n",
       " [5, 67, 26, 19, 256, 6, 336, 809, 23, 19, 6, 697, 408, 10, 1815],\n",
       " [26, 5],\n",
       " [26, 5, 50],\n",
       " [26, 5, 50, 654],\n",
       " [26, 5, 50, 654, 353],\n",
       " [26, 5, 50, 654, 353, 302],\n",
       " [26, 5, 50, 654, 353, 302, 13],\n",
       " [26, 5, 50, 654, 353, 302, 13, 103],\n",
       " [26, 5, 50, 654, 353, 302, 13, 103, 4],\n",
       " [26, 5, 50, 654, 353, 302, 13, 103, 4, 1544],\n",
       " [26, 5, 50, 654, 353, 302, 13, 103, 4, 1544, 2],\n",
       " [26, 5, 50, 654, 353, 302, 13, 103, 4, 1544, 2, 1816],\n",
       " [26, 5, 50, 654, 353, 302, 13, 103, 4, 1544, 2, 1816, 6],\n",
       " [4045, 103],\n",
       " [4045, 103, 2],\n",
       " [4045, 103, 2, 6],\n",
       " [4045, 103, 2, 6, 4046],\n",
       " [4045, 103, 2, 6, 4046, 7],\n",
       " [4045, 103, 2, 6, 4046, 7, 1],\n",
       " [4045, 103, 2, 6, 4046, 7, 1, 354],\n",
       " [4045, 103, 2, 6, 4046, 7, 1, 354, 44],\n",
       " [4045, 103, 2, 6, 4046, 7, 1, 354, 44, 10],\n",
       " [4045, 103, 2, 6, 4046, 7, 1, 354, 44, 10, 337],\n",
       " [4045, 103, 2, 6, 4046, 7, 1, 354, 44, 10, 337, 80],\n",
       " [4045, 103, 2, 6, 4046, 7, 1, 354, 44, 10, 337, 80, 1],\n",
       " [249, 2],\n",
       " [249, 2, 241],\n",
       " [249, 2, 241, 26],\n",
       " [249, 2, 241, 26, 75],\n",
       " [249, 2, 241, 26, 75, 7],\n",
       " [249, 2, 241, 26, 75, 7, 13],\n",
       " [249, 2, 241, 26, 75, 7, 13, 312],\n",
       " [249, 2, 241, 26, 75, 7, 13, 312, 2208],\n",
       " [249, 2, 241, 26, 75, 7, 13, 312, 2208, 655],\n",
       " [4047, 2831],\n",
       " [4047, 2831, 11],\n",
       " [4047, 2831, 11, 10],\n",
       " [4047, 2831, 11, 10, 175],\n",
       " [4047, 2831, 11, 10, 175, 3],\n",
       " [4047, 2831, 11, 10, 175, 3, 88],\n",
       " [4047, 2831, 11, 10, 175, 3, 88, 140],\n",
       " [4047, 2831, 11, 10, 175, 3, 88, 140, 8],\n",
       " [4047, 2831, 11, 10, 175, 3, 88, 140, 8, 11],\n",
       " [4047, 2831, 11, 10, 175, 3, 88, 140, 8, 11, 16],\n",
       " [4047, 2831, 11, 10, 175, 3, 88, 140, 8, 11, 16, 191],\n",
       " [40, 338],\n",
       " [40, 338, 2],\n",
       " [40, 338, 2, 6],\n",
       " [40, 338, 2, 6, 194],\n",
       " [40, 338, 2, 6, 194, 1338],\n",
       " [40, 338, 2, 6, 194, 1338, 295],\n",
       " [40, 338, 2, 6, 194, 1338, 295, 3],\n",
       " [40, 338, 2, 6, 194, 1338, 295, 3, 158],\n",
       " [40, 338, 2, 6, 194, 1338, 295, 3, 158, 11],\n",
       " [338, 3],\n",
       " [338, 3, 221],\n",
       " [187, 3],\n",
       " [187, 3, 77],\n",
       " [187, 3, 77, 16],\n",
       " [187, 3, 77, 16, 180],\n",
       " [187, 3, 77, 16, 180, 6],\n",
       " [187, 3, 77, 16, 180, 6, 63],\n",
       " [187, 3, 77, 16, 180, 6, 63, 81],\n",
       " [187, 3, 77, 16, 180, 6, 63, 81, 101],\n",
       " [187, 3, 77, 16, 180, 6, 63, 81, 101, 6],\n",
       " [187, 3, 77, 16, 180, 6, 63, 81, 101, 6, 1817],\n",
       " [187, 3, 77, 16, 180, 6, 63, 81, 101, 6, 1817, 81],\n",
       " [187, 3, 77, 16, 180, 6, 63, 81, 101, 6, 1817, 81, 3],\n",
       " [733, 140],\n",
       " [733, 140, 2],\n",
       " [733, 140, 2, 7],\n",
       " [733, 140, 2, 7, 807],\n",
       " [733, 140, 2, 7, 807, 208],\n",
       " [733, 140, 2, 7, 807, 208, 3],\n",
       " [733, 140, 2, 7, 807, 208, 3, 585],\n",
       " [733, 140, 2, 7, 807, 208, 3, 585, 11],\n",
       " [733, 140, 2, 7, 807, 208, 3, 585, 11, 86],\n",
       " [733, 140, 2, 7, 807, 208, 3, 585, 11, 86, 24],\n",
       " [733, 140, 2, 7, 807, 208, 3, 585, 11, 86, 24, 151],\n",
       " [733, 140, 2, 7, 807, 208, 3, 585, 11, 86, 24, 151, 26],\n",
       " [8, 11],\n",
       " [8, 11, 4048],\n",
       " [8, 11, 4048, 5],\n",
       " [8, 11, 4048, 5, 136],\n",
       " [8, 11, 4048, 5, 136, 58],\n",
       " [8, 11, 4048, 5, 136, 58, 2832],\n",
       " [44, 96],\n",
       " [44, 96, 61],\n",
       " [44, 96, 61, 11],\n",
       " [44, 96, 61, 11, 79],\n",
       " [3, 67],\n",
       " [3, 67, 9],\n",
       " [3, 67, 9, 3],\n",
       " [3, 67, 9, 3, 734],\n",
       " [3, 67, 9, 3, 734, 9],\n",
       " [3, 67, 9, 3, 734, 9, 96],\n",
       " [3, 67, 9, 3, 734, 9, 96, 61],\n",
       " [3, 67, 9, 3, 734, 9, 96, 61, 3],\n",
       " [3, 67, 9, 3, 734, 9, 96, 61, 3, 79],\n",
       " [3, 67, 9, 3, 734, 9, 96, 61, 3, 79, 8],\n",
       " [3, 67, 9, 3, 734, 9, 96, 61, 3, 79, 8, 11],\n",
       " [3, 67, 9, 3, 734, 9, 96, 61, 3, 79, 8, 11, 16],\n",
       " [3, 67, 9, 3, 734, 9, 96, 61, 3, 79, 8, 11, 16, 39],\n",
       " [3, 67, 9, 3, 734, 9, 96, 61, 3, 79, 8, 11, 16, 39, 1545],\n",
       " [283, 37],\n",
       " [283, 37, 2209],\n",
       " [283, 37, 2209, 1331],\n",
       " [283, 37, 2209, 1331, 2],\n",
       " [283, 37, 2209, 1331, 2, 8],\n",
       " [283, 37, 2209, 1331, 2, 8, 11],\n",
       " [283, 37, 2209, 1331, 2, 8, 11, 16],\n",
       " [283, 37, 2209, 1331, 2, 8, 11, 16, 6],\n",
       " [283, 37, 2209, 1331, 2, 8, 11, 16, 6, 154],\n",
       " [283, 37, 2209, 1331, 2, 8, 11, 16, 6, 154, 4049],\n",
       " [283, 37, 2209, 1331, 2, 8, 11, 16, 6, 154, 4049, 2],\n",
       " [4050, 1339],\n",
       " [4050, 1339, 614],\n",
       " [15, 274],\n",
       " [15, 274, 33],\n",
       " [15, 274, 33, 32],\n",
       " [15, 274, 33, 32, 3],\n",
       " [15, 274, 33, 32, 3, 31],\n",
       " [15, 274, 33, 32, 3, 31, 14],\n",
       " [15, 274, 33, 32, 3, 31, 14, 159],\n",
       " [15, 274, 33, 32, 3, 31, 14, 159, 115],\n",
       " [15, 274, 33, 32, 3, 31, 14, 159, 115, 11],\n",
       " [15, 274, 33, 32, 3, 31, 14, 159, 115, 11, 54],\n",
       " [15, 274, 33, 32, 3, 31, 14, 159, 115, 11, 54, 257],\n",
       " [15, 274, 33, 32, 3, 31, 14, 159, 115, 11, 54, 257, 16],\n",
       " [39, 1546],\n",
       " [39, 1546, 18],\n",
       " [39, 1546, 18, 11],\n",
       " [39, 1546, 18, 11, 735],\n",
       " [39, 1546, 18, 11, 735, 6],\n",
       " [39, 1546, 18, 11, 735, 6, 161],\n",
       " [39, 1546, 18, 11, 735, 6, 161, 4051],\n",
       " [39, 1546, 18, 11, 735, 6, 161, 4051, 385],\n",
       " [39, 1546, 18, 11, 735, 6, 161, 4051, 385, 9],\n",
       " [39, 1546, 18, 11, 735, 6, 161, 4051, 385, 9, 14],\n",
       " [39, 1546, 18, 11, 735, 6, 161, 4051, 385, 9, 14, 386],\n",
       " [39, 1546, 18, 11, 735, 6, 161, 4051, 385, 9, 14, 386, 8],\n",
       " [39, 1546, 18, 11, 735, 6, 161, 4051, 385, 9, 14, 386, 8, 3],\n",
       " [39, 1546, 18, 11, 735, 6, 161, 4051, 385, 9, 14, 386, 8, 3, 18],\n",
       " [6, 306],\n",
       " [6, 306, 698],\n",
       " [6, 306, 698, 40],\n",
       " [6, 306, 698, 40, 2833],\n",
       " [6, 306, 698, 40, 2833, 2],\n",
       " [6, 306, 698, 40, 2833, 2, 95],\n",
       " [6, 306, 698, 40, 2833, 2, 95, 219],\n",
       " [6, 306, 698, 40, 2833, 2, 95, 219, 7],\n",
       " [6, 306, 698, 40, 2833, 2, 95, 219, 7, 6],\n",
       " [6, 306, 698, 40, 2833, 2, 95, 219, 7, 6, 810],\n",
       " [6, 306, 698, 40, 2833, 2, 95, 219, 7, 6, 810, 4052],\n",
       " [6, 306, 698, 40, 2833, 2, 95, 219, 7, 6, 810, 4052, 23],\n",
       " [6, 306, 698, 40, 2833, 2, 95, 219, 7, 6, 810, 4052, 23, 17],\n",
       " [6, 306, 698, 40, 2833, 2, 95, 219, 7, 6, 810, 4052, 23, 17, 3],\n",
       " [16, 2834],\n",
       " [16, 2834, 15],\n",
       " [16, 2834, 15, 484],\n",
       " [16, 2834, 15, 484, 3],\n",
       " [16, 2834, 15, 484, 3, 811],\n",
       " [16, 2834, 15, 484, 3, 811, 409],\n",
       " [16, 2834, 15, 484, 3, 811, 409, 96],\n",
       " [16, 2834, 15, 484, 3, 811, 409, 96, 11],\n",
       " [16, 2834, 15, 484, 3, 811, 409, 96, 11, 734],\n",
       " [16, 2834, 15, 484, 3, 811, 409, 96, 11, 734, 9],\n",
       " [16, 2834, 15, 484, 3, 811, 409, 96, 11, 734, 9, 17],\n",
       " [16, 2834, 15, 484, 3, 811, 409, 96, 11, 734, 9, 17, 5],\n",
       " [16, 2834, 15, 484, 3, 811, 409, 96, 11, 734, 9, 17, 5, 1172],\n",
       " [4053, 38],\n",
       " [4053, 38, 14],\n",
       " [4053, 38, 14, 4054],\n",
       " [4053, 38, 14, 4054, 2],\n",
       " [4053, 38, 14, 4054, 2, 15],\n",
       " [4053, 38, 14, 4054, 2, 15, 250],\n",
       " [4053, 38, 14, 4054, 2, 15, 250, 57],\n",
       " [4053, 38, 14, 4054, 2, 15, 250, 57, 387],\n",
       " [4053, 38, 14, 4054, 2, 15, 250, 57, 387, 36],\n",
       " [4053, 38, 14, 4054, 2, 15, 250, 57, 387, 36, 1340],\n",
       " [4053, 38, 14, 4054, 2, 15, 250, 57, 387, 36, 1340, 23],\n",
       " [29, 208],\n",
       " [29, 208, 3],\n",
       " [29, 208, 3, 1341],\n",
       " [29, 208, 3, 1341, 5],\n",
       " [29, 208, 3, 1341, 5, 67],\n",
       " [29, 208, 3, 1341, 5, 67, 96],\n",
       " [29, 208, 3, 1341, 5, 67, 96, 11],\n",
       " [29, 208, 3, 1341, 5, 67, 96, 11, 224],\n",
       " [29, 208, 3, 1341, 5, 67, 96, 11, 224, 9],\n",
       " [29, 208, 3, 1341, 5, 67, 96, 11, 224, 9, 52],\n",
       " [10, 1173],\n",
       " [10, 1173, 5],\n",
       " [10, 1173, 5, 171],\n",
       " [10, 1173, 5, 171, 2],\n",
       " [10, 1173, 5, 171, 2, 2835],\n",
       " [10, 1173, 5, 171, 2, 2835, 13],\n",
       " [10, 1173, 5, 171, 2, 2835, 13, 143],\n",
       " [10, 1173, 5, 171, 2, 2835, 13, 143, 955],\n",
       " [10, 1173, 5, 171, 2, 2835, 13, 143, 955, 186],\n",
       " [10, 1173, 5, 171, 2, 2835, 13, 143, 955, 186, 339],\n",
       " [9, 14],\n",
       " [9, 14, 4055],\n",
       " [9, 14, 4055, 699],\n",
       " [9, 14, 4055, 699, 32],\n",
       " [9, 14, 4055, 699, 32, 10],\n",
       " [9, 14, 4055, 699, 32, 10, 15],\n",
       " [9, 14, 4055, 699, 32, 10, 15, 148],\n",
       " [9, 14, 4055, 699, 32, 10, 15, 148, 151],\n",
       " [9, 14, 4055, 699, 32, 10, 15, 148, 151, 26],\n",
       " [9, 14, 4055, 699, 32, 10, 15, 148, 151, 26, 8],\n",
       " [9, 14, 4055, 699, 32, 10, 15, 148, 151, 26, 8, 40],\n",
       " [9, 14, 4055, 699, 32, 10, 15, 148, 151, 26, 8, 40, 1],\n",
       " [736, 4],\n",
       " [736, 4, 45],\n",
       " [736, 4, 45, 132],\n",
       " [736, 4, 45, 132, 4056],\n",
       " [736, 4, 45, 132, 4056, 101],\n",
       " [736, 4, 45, 132, 4056, 101, 110],\n",
       " [736, 4, 45, 132, 4056, 101, 110, 1],\n",
       " [736, 4, 45, 132, 4056, 101, 110, 1, 4057],\n",
       " [736, 4, 45, 132, 4056, 101, 110, 1, 4057, 2836],\n",
       " [736, 4, 45, 132, 4056, 101, 110, 1, 4057, 2836, 9],\n",
       " [736, 4, 45, 132, 4056, 101, 110, 1, 4057, 2836, 9, 1],\n",
       " [1342, 14],\n",
       " [1342, 14, 2837],\n",
       " [1342, 14, 2837, 48],\n",
       " [1342, 14, 2837, 48, 410],\n",
       " [1342, 14, 2837, 48, 410, 700],\n",
       " [1342, 14, 2837, 48, 410, 700, 2210],\n",
       " [1342, 14, 2837, 48, 410, 700, 2210, 2838],\n",
       " [1342, 14, 2837, 48, 410, 700, 2210, 2838, 1547],\n",
       " [1342, 14, 2837, 48, 410, 700, 2210, 2838, 1547, 72],\n",
       " [1342, 14, 2837, 48, 410, 700, 2210, 2838, 1547, 72, 16],\n",
       " [39, 737],\n",
       " [39, 737, 48],\n",
       " [39, 737, 48, 701],\n",
       " [39, 737, 48, 701, 64],\n",
       " [39, 737, 48, 701, 64, 57],\n",
       " [39, 737, 48, 701, 64, 57, 37],\n",
       " [39, 737, 48, 701, 64, 57, 37, 2211],\n",
       " [39, 737, 48, 701, 64, 57, 37, 2211, 2839],\n",
       " [39, 737, 48, 701, 64, 57, 37, 2211, 2839, 173],\n",
       " [39, 737, 48, 701, 64, 57, 37, 2211, 2839, 173, 1],\n",
       " [2212, 4],\n",
       " [2212, 4, 1],\n",
       " [2212, 4, 1, 4058],\n",
       " [2212, 4, 1, 4058, 7],\n",
       " [2212, 4, 1, 4058, 7, 546],\n",
       " [2212, 4, 1, 4058, 7, 546, 5],\n",
       " [2212, 4, 1, 4058, 7, 546, 5, 1548],\n",
       " [2212, 4, 1, 4058, 7, 546, 5, 1548, 4059],\n",
       " [2212, 4, 1, 4058, 7, 546, 5, 1548, 4059, 1549],\n",
       " [2212, 4, 1, 4058, 7, 546, 5, 1548, 4059, 1549, 28],\n",
       " [2212, 4, 1, 4058, 7, 546, 5, 1548, 4059, 1549, 28, 9],\n",
       " [2212, 4, 1, 4058, 7, 546, 5, 1548, 4059, 1549, 28, 9, 1550],\n",
       " [2212, 4, 1, 4058, 7, 546, 5, 1548, 4059, 1549, 28, 9, 1550, 11],\n",
       " [67, 15],\n",
       " [67, 15, 738],\n",
       " [67, 15, 738, 1818],\n",
       " [67, 15, 738, 1818, 8],\n",
       " [67, 15, 738, 1818, 8, 11],\n",
       " [67, 15, 738, 1818, 8, 11, 18],\n",
       " [67, 15, 738, 1818, 8, 11, 18, 39],\n",
       " [67, 15, 738, 1818, 8, 11, 18, 39, 52],\n",
       " [67, 15, 738, 1818, 8, 11, 18, 39, 52, 7],\n",
       " [67, 15, 738, 1818, 8, 11, 18, 39, 52, 7, 2213],\n",
       " [67, 15, 738, 1818, 8, 11, 18, 39, 52, 7, 2213, 1551],\n",
       " [67, 15, 738, 1818, 8, 11, 18, 39, 52, 7, 2213, 1551, 2],\n",
       " [8, 11],\n",
       " [8, 11, 18],\n",
       " [8, 11, 18, 6],\n",
       " [8, 11, 18, 6, 1537],\n",
       " [8, 11, 18, 6, 1537, 4060],\n",
       " [8, 11, 18, 6, 1537, 4060, 2214],\n",
       " [8, 11, 18, 6, 1537, 4060, 2214, 4061],\n",
       " [8, 11, 18, 6, 1537, 4060, 2214, 4061, 4062],\n",
       " [8, 11, 18, 6, 1537, 4060, 2214, 4061, 4062, 4],\n",
       " [8, 11, 18, 6, 1537, 4060, 2214, 4061, 4062, 4, 1],\n",
       " [275, 4063],\n",
       " [275, 4063, 17],\n",
       " [275, 4063, 17, 5],\n",
       " [275, 4063, 17, 5, 45],\n",
       " [275, 4063, 17, 5, 45, 807],\n",
       " [275, 4063, 17, 5, 45, 807, 66],\n",
       " [275, 4063, 17, 5, 45, 807, 66, 6],\n",
       " [275, 4063, 17, 5, 45, 807, 66, 6, 269],\n",
       " [275, 4063, 17, 5, 45, 807, 66, 6, 269, 1819],\n",
       " [275, 4063, 17, 5, 45, 807, 66, 6, 269, 1819, 58],\n",
       " [275, 4063, 17, 5, 45, 807, 66, 6, 269, 1819, 58, 15],\n",
       " [422, 2840],\n",
       " [422, 2840, 4],\n",
       " [422, 2840, 4, 4064],\n",
       " [422, 2840, 4, 4064, 19],\n",
       " [422, 2840, 4, 4064, 19, 6],\n",
       " [422, 2840, 4, 4064, 19, 6, 233],\n",
       " [422, 2840, 4, 4064, 19, 6, 233, 956],\n",
       " [422, 2840, 4, 4064, 19, 6, 233, 956, 4],\n",
       " [422, 2840, 4, 4064, 19, 6, 233, 956, 4, 4065],\n",
       " [422, 2840, 4, 4064, 19, 6, 233, 956, 4, 4065, 4],\n",
       " [422, 2840, 4, 4064, 19, 6, 233, 956, 4, 4065, 4, 2215],\n",
       " [30, 13],\n",
       " [30, 13, 122],\n",
       " [30, 13, 122, 1820],\n",
       " [30, 13, 122, 1820, 2],\n",
       " [30, 13, 122, 1820, 2, 6],\n",
       " [30, 13, 122, 1820, 2, 6, 4066],\n",
       " [30, 13, 122, 1820, 2, 6, 4066, 40],\n",
       " [30, 13, 122, 1820, 2, 6, 4066, 40, 1],\n",
       " [30, 13, 122, 1820, 2, 6, 4066, 40, 1, 122],\n",
       " [30, 13, 122, 1820, 2, 6, 4066, 40, 1, 122, 141],\n",
       " [30, 13, 122, 1820, 2, 6, 4066, 40, 1, 122, 141, 4],\n",
       " [30, 13, 122, 1820, 2, 6, 4066, 40, 1, 122, 141, 4, 13],\n",
       " [656, 215],\n",
       " [656, 215, 5],\n",
       " [656, 215, 5, 702],\n",
       " [656, 215, 5, 702, 110],\n",
       " [656, 215, 5, 702, 110, 10],\n",
       " [656, 215, 5, 702, 110, 10, 57],\n",
       " [656, 215, 5, 702, 110, 10, 57, 4067],\n",
       " [656, 215, 5, 702, 110, 10, 57, 4067, 13],\n",
       " [656, 215, 5, 702, 110, 10, 57, 4067, 13, 4068],\n",
       " [656, 215, 5, 702, 110, 10, 57, 4067, 13, 4068, 3],\n",
       " [656, 215, 5, 702, 110, 10, 57, 4067, 13, 4068, 3, 89],\n",
       " [656, 215, 5, 702, 110, 10, 57, 4067, 13, 4068, 3, 89, 25],\n",
       " [1174, 187],\n",
       " [1174, 187, 66],\n",
       " [1174, 187, 66, 3],\n",
       " [1174, 187, 66, 3, 61],\n",
       " [1174, 187, 66, 3, 61, 24],\n",
       " [1174, 187, 66, 3, 61, 24, 2841],\n",
       " [1174, 187, 66, 3, 61, 24, 2841, 35],\n",
       " [1174, 187, 66, 3, 61, 24, 2841, 35, 5],\n",
       " [1174, 187, 66, 3, 61, 24, 2841, 35, 5, 25],\n",
       " [1174, 187, 66, 3, 61, 24, 2841, 35, 5, 25, 50],\n",
       " [1174, 187, 66, 3, 61, 24, 2841, 35, 5, 25, 50, 2842],\n",
       " [1174, 187, 66, 3, 61, 24, 2841, 35, 5, 25, 50, 2842, 1821],\n",
       " [1174, 187, 66, 3, 61, 24, 2841, 35, 5, 25, 50, 2842, 1821, 4],\n",
       " [1174, 187, 66, 3, 61, 24, 2841, 35, 5, 25, 50, 2842, 1821, 4, 1],\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pad Sequences\n",
    "max_sequences_len = max([len(x) for x in input_sequences])\n",
    "max_sequences_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    1, 1534],\n",
       "       [   0,    0,    0, ...,    1, 1534,    4],\n",
       "       [   0,    0,    0, ..., 1534,    4,  118],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1199,   18,  476],\n",
       "       [   0,    0,    0, ...,   18,  476,   15],\n",
       "       [   0,    0,    0, ...,  476,   15,  383]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences =np.array(pad_sequences(input_sequences,maxlen = max_sequences_len,padding = \"pre\"))\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictor and label\n",
    "import tensorflow as tf\n",
    "x,y = input_sequences[:,:-1],input_sequences[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,    1],\n",
       "       [   0,    0,    0, ...,    0,    1, 1534],\n",
       "       [   0,    0,    0, ...,    1, 1534,    4],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 3598, 1199,   18],\n",
       "       [   0,    0,    0, ..., 1199,   18,  476],\n",
       "       [   0,    0,    0, ...,   18,  476,   15]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1534,    4,  118, ...,  476,   15,  383])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y,num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # where the index present it represent as 1 remaning all represent with 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62602, 16), (62602, 7507))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim = 8200,output_dim = 17), \n",
    "    tf.keras.layers.LSTM(units = 200),\n",
    "    tf.keras.layers.Dense(total_words, activation = tf.nn.softmax)\n",
    "])\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam' , metrics = ['Accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">62602</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">139,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">62602</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">174,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">62602</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7507</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,508,907</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m62602\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │       \u001b[38;5;34m139,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m62602\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │       \u001b[38;5;34m174,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m62602\u001b[0m, \u001b[38;5;34m7507\u001b[0m)          │     \u001b[38;5;34m1,508,907\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,822,707</span> (6.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,822,707\u001b[0m (6.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,822,707</span> (6.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,822,707\u001b[0m (6.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "model(np.array(x_train))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 74ms/step - Accuracy: 0.0567 - loss: 6.9073\n",
      "Epoch 2/100\n",
      "\u001b[1m  1/490\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 140ms/step - Accuracy: 0.0703 - loss: 6.1029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DL_project_2\\dpl\\lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: Accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 69ms/step - Accuracy: 0.0660 - loss: 6.1990\n",
      "Epoch 3/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 57ms/step - Accuracy: 0.0730 - loss: 6.0071\n",
      "Epoch 4/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 57ms/step - Accuracy: 0.0763 - loss: 5.8747\n",
      "Epoch 5/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 57ms/step - Accuracy: 0.0873 - loss: 5.7153\n",
      "Epoch 6/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 57ms/step - Accuracy: 0.1056 - loss: 5.5387\n",
      "Epoch 7/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 59ms/step - Accuracy: 0.1189 - loss: 5.3715\n",
      "Epoch 8/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 73ms/step - Accuracy: 0.1254 - loss: 5.2172\n",
      "Epoch 9/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 76ms/step - Accuracy: 0.1327 - loss: 5.0902\n",
      "Epoch 10/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 63ms/step - Accuracy: 0.1433 - loss: 4.9545\n",
      "Epoch 11/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 58ms/step - Accuracy: 0.1446 - loss: 4.8193\n",
      "Epoch 12/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - Accuracy: 0.1516 - loss: 4.7055\n",
      "Epoch 13/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 58ms/step - Accuracy: 0.1597 - loss: 4.5715\n",
      "Epoch 14/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - Accuracy: 0.1633 - loss: 4.4483\n",
      "Epoch 15/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 58ms/step - Accuracy: 0.1703 - loss: 4.3600\n",
      "Epoch 16/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 59ms/step - Accuracy: 0.1762 - loss: 4.2495\n",
      "Epoch 17/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 60ms/step - Accuracy: 0.1863 - loss: 4.1369\n",
      "Epoch 18/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.1996 - loss: 4.0277\n",
      "Epoch 19/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 53ms/step - Accuracy: 0.2106 - loss: 3.9361\n",
      "Epoch 20/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 54ms/step - Accuracy: 0.2217 - loss: 3.8497\n",
      "Epoch 21/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.2353 - loss: 3.7603\n",
      "Epoch 22/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.2471 - loss: 3.6722\n",
      "Epoch 23/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 53ms/step - Accuracy: 0.2558 - loss: 3.5912\n",
      "Epoch 24/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - Accuracy: 0.2682 - loss: 3.5216\n",
      "Epoch 25/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 53ms/step - Accuracy: 0.2784 - loss: 3.4473\n",
      "Epoch 26/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 56ms/step - Accuracy: 0.2934 - loss: 3.3894\n",
      "Epoch 27/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 57ms/step - Accuracy: 0.3009 - loss: 3.3117\n",
      "Epoch 28/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 53ms/step - Accuracy: 0.3106 - loss: 3.2482\n",
      "Epoch 29/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 53ms/step - Accuracy: 0.3184 - loss: 3.1938\n",
      "Epoch 30/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 53ms/step - Accuracy: 0.3317 - loss: 3.1231\n",
      "Epoch 31/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 51ms/step - Accuracy: 0.3389 - loss: 3.0694\n",
      "Epoch 32/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - Accuracy: 0.3514 - loss: 3.0087\n",
      "Epoch 33/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - Accuracy: 0.3618 - loss: 2.9658\n",
      "Epoch 34/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - Accuracy: 0.3716 - loss: 2.9061\n",
      "Epoch 35/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 54ms/step - Accuracy: 0.3781 - loss: 2.8606\n",
      "Epoch 36/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.3854 - loss: 2.8124\n",
      "Epoch 37/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.3949 - loss: 2.7617\n",
      "Epoch 38/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 56ms/step - Accuracy: 0.4031 - loss: 2.7146\n",
      "Epoch 39/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4071 - loss: 2.6703\n",
      "Epoch 40/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4184 - loss: 2.6360\n",
      "Epoch 41/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4280 - loss: 2.5869\n",
      "Epoch 42/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4367 - loss: 2.5525\n",
      "Epoch 43/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4482 - loss: 2.4867\n",
      "Epoch 44/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.4529 - loss: 2.4559\n",
      "Epoch 45/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4621 - loss: 2.4147\n",
      "Epoch 46/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4679 - loss: 2.3820\n",
      "Epoch 47/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4782 - loss: 2.3376\n",
      "Epoch 48/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.4831 - loss: 2.3049\n",
      "Epoch 49/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4919 - loss: 2.2636\n",
      "Epoch 50/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.4984 - loss: 2.2327\n",
      "Epoch 51/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 57ms/step - Accuracy: 0.5040 - loss: 2.1981\n",
      "Epoch 52/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.5133 - loss: 2.1739\n",
      "Epoch 53/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.5180 - loss: 2.1402\n",
      "Epoch 54/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.5266 - loss: 2.0941\n",
      "Epoch 55/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.5363 - loss: 2.0579\n",
      "Epoch 56/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.5394 - loss: 2.0441\n",
      "Epoch 57/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.5483 - loss: 1.9990\n",
      "Epoch 58/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.5540 - loss: 1.9792\n",
      "Epoch 59/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.5606 - loss: 1.9395\n",
      "Epoch 60/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.5662 - loss: 1.9215\n",
      "Epoch 61/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.5737 - loss: 1.8856\n",
      "Epoch 62/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.5768 - loss: 1.8718\n",
      "Epoch 63/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.5851 - loss: 1.8421\n",
      "Epoch 64/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.5872 - loss: 1.8279\n",
      "Epoch 65/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.5965 - loss: 1.7808\n",
      "Epoch 66/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6033 - loss: 1.7515\n",
      "Epoch 67/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6082 - loss: 1.7355\n",
      "Epoch 68/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - Accuracy: 0.6136 - loss: 1.7090\n",
      "Epoch 69/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.6213 - loss: 1.6841\n",
      "Epoch 70/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - Accuracy: 0.6245 - loss: 1.6603\n",
      "Epoch 71/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6296 - loss: 1.6400\n",
      "Epoch 72/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6365 - loss: 1.6088\n",
      "Epoch 73/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6399 - loss: 1.5916\n",
      "Epoch 74/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6449 - loss: 1.5771\n",
      "Epoch 75/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6485 - loss: 1.5532\n",
      "Epoch 76/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6532 - loss: 1.5310\n",
      "Epoch 77/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6536 - loss: 1.5190\n",
      "Epoch 78/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6642 - loss: 1.4869\n",
      "Epoch 79/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6703 - loss: 1.4565\n",
      "Epoch 80/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6727 - loss: 1.4534\n",
      "Epoch 81/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6724 - loss: 1.4389\n",
      "Epoch 82/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6845 - loss: 1.4033\n",
      "Epoch 83/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6835 - loss: 1.3941\n",
      "Epoch 84/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6908 - loss: 1.3799\n",
      "Epoch 85/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 57ms/step - Accuracy: 0.6936 - loss: 1.3616\n",
      "Epoch 86/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.6977 - loss: 1.3385\n",
      "Epoch 87/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - Accuracy: 0.6980 - loss: 1.3204\n",
      "Epoch 88/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.7082 - loss: 1.3030\n",
      "Epoch 89/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 59ms/step - Accuracy: 0.7077 - loss: 1.2959\n",
      "Epoch 90/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 55ms/step - Accuracy: 0.7139 - loss: 1.2775\n",
      "Epoch 91/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.7197 - loss: 1.2516\n",
      "Epoch 92/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.7204 - loss: 1.2425\n",
      "Epoch 93/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.7235 - loss: 1.2280\n",
      "Epoch 94/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.7304 - loss: 1.2018\n",
      "Epoch 95/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.7375 - loss: 1.1791\n",
      "Epoch 96/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.7345 - loss: 1.1834\n",
      "Epoch 97/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - Accuracy: 0.7364 - loss: 1.1682\n",
      "Epoch 98/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.7417 - loss: 1.1532\n",
      "Epoch 99/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - Accuracy: 0.7436 - loss: 1.1457\n",
      "Epoch 100/100\n",
      "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 56ms/step - Accuracy: 0.7460 - loss: 1.1369\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100,\n",
    "                    batch_size=128, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def predict_next_word(model,tokenizer,text,max_sequences_len):\n",
    "#     token_list  = tokenizer.texts_to_sequences([text][0])\n",
    "#     if len(token_list) >= max_sequences_len:\n",
    "#         token_list = token_list[-(max_sequences_len-1):]\n",
    "#     token_list = pad_sequences([token_list],maxlen= max_sequences_len-1,padding=\"pre\")\n",
    "#     predicted = model.predict(token_list,verbose=0)\n",
    "#     predicted_word_index = np.argmax(predicted,axis=1)\n",
    "#     for word,index in tokenizer.word_index.items():\n",
    "#         if index == predicted_word_index:\n",
    "#             return word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, tokenizer, input_text, max_sequences_len):\n",
    "    token_list = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    \n",
    "    # Adjust token_list length if needed\n",
    "    if len(token_list) >= max_sequences_len:\n",
    "        token_list = token_list[-(max_sequences_len - 1):]\n",
    "    elif len(token_list) < max_sequences_len - 1:\n",
    "        token_list = [0] * (max_sequences_len - 1 - len(token_list)) + token_list  # Pad manually if needed\n",
    "    \n",
    "    # Convert to a padded sequence\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequences_len - 1, padding=\"pre\")\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=1)\n",
    "    \n",
    "    # Convert prediction to word\n",
    "    predicted_word = tokenizer.index_word[predicted_word_index[0]]\n",
    "    return predicted_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:i want to be able to  \n",
      "Next Word prediction :look\n"
     ]
    }
   ],
   "source": [
    "input_text = \"i want to be able to \"\n",
    "print(f\"Input text:{input_text}\")\n",
    "max_sequences_len = model.input_shape[1]+1\n",
    "next_word = predict_next_word(model,tokenizer,input_text,max_sequences_len)\n",
    "print(f\"Next Word prediction :{next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
